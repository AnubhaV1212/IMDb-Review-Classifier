{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Dataset of 50K Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB dataset having 50K movie reviews for Text classification using Multinomial Naive Bayes.\n",
    "\n",
    "This is a dataset for binary sentiment classification.\n",
    "\n",
    "We provide a set of 25,000 highly polar movie reviews for training and 25,000 for testing.\n",
    "\n",
    "For more dataset information, please go through the following link,\n",
    "http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "Data Source: https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split , KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
    "import re\n",
    "import string\n",
    "# Library for stopwords\n",
    "from nltk.corpus import stopwords\n",
    "# Library for Stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "# Library for Lemmatizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the dataset\n",
    "df = pd.read_csv('IMDB dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# to check the structure of dataset and is there any null value\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# priniting top 5 rows to have a look on how data look like\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive    25000\n",
      "negative    25000\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.sentiment.value_counts())      # print(dataset['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation 1.1\n",
    "1. Dataset have 2 columns i.e. Review and Sentiment\n",
    "2. Review on whatever written by user and sentiment is whether they like the movie or not \n",
    "3. Dataset is of binary classification type, since sentiment is either positive, if user like the movie or negative, if user dislike the movie\n",
    "4. Dataset have no null value and it is balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49582\n"
     ]
    }
   ],
   "source": [
    "print(len(set(df.review)))    #remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review\n",
      "\b\b\b\bA Turkish Bath sequence in a film noir located in New York in the 50's, that must be a hint at something ! Something that curiously, in all the previous comments, no one has pointed out , but seems to me essential to the understanding of this movie <br /><br />the Turkish Baths sequence: a back street at night, the entrance of a sleazy sauna, and Scalise wrapped in a sheet, getting his thighs massaged. Steve, the masseur is of the young rough boxer ( Beefcake!) type , and another guy, a bodyguard? finishes dressing up. Dixon obviously hates what he sees there and gets rough right away. We know he has a reputation for roughing up suspects. Good cop but getting out of control easy. Why is it that he hates them so much ? <br /><br />Could it be that he hates himself. This part of himself he inherited from his father ? That dark side that could lead him right at the end of the sidewalk, into the gutter ? What if that dark side lurked within a \"closet\" ? Remember : whenever Dixon meets Scalise ( 3 times), the guy is lying on a bed, and he only has men around him for company ( the irony of the \" Girls\" poster pinned up on the wall near his bed !).<br /><br />Scalise acts funny: affected manners, cranking his neck arrogantly, defiant, shoving his inhalator ( poppers ?) into his nostrils each time he talks to Dixon. Dixon, with a vengeance, is bent on pinning down Scalise who seems not to understand : \"I never saw a man so full of hate as you. I consider it almost humorous the way you came after me alone. \" Four years jumping at me as if I was somebody special! Why? \"<br /><br />Because Scalise is someone special indeed : he is the direct inheritor of Dixon's father : \" Your father liked me\", \"Your father set me up in business\". He stands as Dixon's criminal brother, his dark side incarnate. And to top it all, he prefers the company of men. Dixon knows it well :\" Who killed him (Paine)? You or one of your playmates?\" Playmates ! Notice how each time they meet, Dixon manhandles Scalise: he picks the address-book out of his jacket, slaps his face, punches him. Scalise : \"I warn you not to touch me! \" . Dixon's homophobia is obvious. Or put it different : his unexpressed homosexuality . Dixon, aka Dixon's kid, is the son of a thief. In reaction to this, he decided to become a cop, a good one, but there is something of the criminal in him, a dark side: he is a violent copper, a murderer, a liar. Besides, he is not married, brings \"a dizzy blonde\" to his familiar eat-out place every now and then, but nothing else. The waitress scoffing says that he doesn't know how to make love to a woman. Dixon has a deep feeling of guilt and hates himself for those reasons.\" A hood and a mobster like his old man. Blood will tell\". Finally, in order to achieve redemption, Dixon decides to sacrifice himself : if he gets his alter ego Scalise to kill him, he will free himself from the guilt and free the girl and her father too.<br /><br />The end of the movie brings us back to the opening sequence : Scalise is pushed in the gutter and Dixon deserves the right to walk the sidewalk and wins the love of the dame. He is straight at last.<br /><br />The unspoken theme of the movie could very well be that of a man who in order to cover his repressed feelings, wants to experience a woman's love ( Jean Douchet)<br /><br />(These notes owe a lot to the film commentary by Jean Douchet in the French DVD edited by CarlottaI                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               1\n",
      "!!! Spoiler alert!!!<br /><br />The point is, though, that I didn't think this film had an ending TO spoil... I only started watching it in the middle, after Matt had gotten into Sarah's body, but then I became fascinated by the bizarreness of the plot, even for a Channel 5 movie... and couldn't possibly see how Matt wld end up happy. What about his fiancee? At one stage looked like he was gonna get with his best friend, surely icky and wrong... and then the whole 'oggi oggi oggi' thing does NOT WORK as a touching buddy-buddy catchphrase, tis just ridiculous... so was going 'surely he can't just come back to life? and yet how can he live as a woman?' and then the film just got over that by ending and not explaining anything at all!!!!! What's that about??? I was so cross, wasted a whole hour of my life for no reason at all!!! :) but was one of the funniest films I've ever seen, so, swings and roundabouts                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  1\n",
      "!!!! MILD SPOILERS !!!!<br /><br />The premise goes like this : A store gets burnt down and assistant Sergio is asked by the father of the man who started the fire to take the wrap to which Sergio agrees .<br /><br />So far so good , but there`s a fair lapse of logic involved Sergio agrees to do this for the sum of 25,000 dollars but why ? Come on guys if you were a good looking white boy would you run the risk of getting a long spell in a tough jail ( A very real possibilty for arson ) for the sake of 25 grand ? I know I wouldn`t , and seeing as you`d have a criminal record no employer would want to touch you with a barge pole so is $25,000 dollars all that much for a life of workfare and welfare cheques ? There`s also something else that seems to have gone without notice from the premise , since Mister Lumpke has told Sergio that his son did the fire he seems unware of the possibility that he may know too much . Wouldn`t alarm bells be ringing in your mind about someone wanting to keep you quite if they told you something ? <br /><br />I guess we`re not suppossed to think about such details since A PYROMANIAC`S LOVE STORY isn`t suppossed to be an intelligent thriller , it`s a light hearted romantic comedy/ chick flick that`s probably best apprieciated as a girls night in . Looking through this comments page it is obvious that the movie has its defenders but as a cynical male I wasn`t too impressed and William Baldwin does go way over the top                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1\n",
      "!!!! MILD SPOILERS !!!!<br /><br />With the exception of THE TERMINATOR and TOTAL RECALL I don`t think Arnie`s action/adventure movies are up to much . They`re better than his comedies for sure but that`s hardly saying much . The problem I have with his all action blockbusters is that they`re overblown and lacking in any sort of morality <br /><br />Morality ? I mentioned in my review of TERMINATOR 2 the scene where good guy Terminator blows the kneecaps off the SWAT team . Are we to think that because the hero maims people doing their job instead of killing them we will admire him in someway ? This is the problem with ERASER , when James Cann`s character is revealed as a traitor within the US Marshal department Arnie`s character John Kruger goes on the run with a witness he`s protecting but in several later sequences Kruger kills a fairly large amount of marshals working with the villain . Are we take it they were all traitors too ? Surely many of them were honest men who were trying to stop Kruger because the bad guy told them Kruger was the traitor ? It`s a rather uneasy thought that Kruger killed several people who were trying to genuinely up hold the law <br /><br />Despite costing one hundred million dollars the special effects aren`t all that impressive . Look at the scene where Kruger lets go of the jet wing and scrambles to put on a parachute . It`s obvious as the action intercuts that it`s a stuntman who`s doing the free fall sequence while Arnie is in a studio in front of a blue screen . ERASER is also a film that has unnecessary CGI featuring killer alligators , not only unnecessary CGI but unconvincing CGI too . There`s also a few plot holes like in the opening scene involving a couple of witness protection people that the mob has caught up with . Kruger opens a car trunk and pulls out a couple of bodies and starts a fire thereby throwing the mob of the scent . Kruger is next seen rearranging the dental records via computer of the couple he`s saved . It would be logical to do this but would ALL the couples dental records be kept on computer ? Most importantly of all are we to believe the US Marshal department keep a freezer full of bodies for such events ?<br /><br />So they`re you go , a typical Arnie thriller long on unlikely set pieces and short on intelligence and it`s interesting to note that ERASER didn`t make much of a profit at the box office as the production costs almost outweighed a potential audience figure . After ERASER Arnie didn`t do much more business at the box office save for TERMINATOR 3 : RISE OF THE MACHINES which was an event movie and it`ll be interesting to see if he`ll be remembered as a politician rather than a movie star                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  1\n",
      "!!!! POSSIBLE MILD SPOILER !!!!!<br /><br />As I watched the first half of GUILTY AS SIN I couldn`t believe it was made in 1993 because it played like a JAGGED EDGE / Joe Eszterhas clone from the mid 80s . It starts with a murder and it`s left for the audience to muse \" Is he guilty or innocent and will he go to bed with his attorney ? \" , but halfway through the film shows its early 90s credentials by turning into a \" Lawyer gets manipulated and stalked by her client \" type film which ends in a ridiculous manner , and GUILTY AS SIN has an even more ridiculous ending in this respect .<br /><br />This is a very poor thriller but the most unforgivable thing about it is that it was directed by Sidney Lumet the same man who brought us the all time classic court room drama 12 ANGRY MEN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ..\n",
      "{Possible spoilers coming up... you've been forewarned.}<br /><br />This is absolutely one of my all time favorite musicals and movie musicals! (The other is Damn Yankees with Gwen Verdon, Tab Hunter and Ray Walston) As we all know, sometimes the luster (not to mention the songs) of a show are lost in its transition from stage to screen. This is, for the most part, DEFINITELY not the case here.<br /><br />The sets are divine, bright and colorful, the characters are bigger than life and you can't help but love them, and Michael Kidd's choreography is absolutely stunning. (So glad to know they used the original Broadway choreographer)<br /><br />All of the actors \"bounce the ball\" (that is, have unbeatable chemistry) to perfection in this film. Frank and Marlon are absolutely believable as the proprietor of the oldest established permanent floating crap game in New York, and the most notorious gambler who bets on even the most minute things-- such as his fever going up to 104 if he doesn't take penicillin. Sweet, fresh faced Jean Simmons is perfect for the role of Sarah (although it is true, her singing pipes are not as outstanding as that of Isabel Bigley or Josie de Guzman)-- the mission doll with a heart of gold and a drive to heal all. And last but certainly not least (on my list anyway) is Miss Vivian Blaine, reprising her Broadway role as Miss Adelaide-- the Hot Box lead singer and dancer who would like to finally end her 14 year engagement to Nathan with marriage, and rid herself of the psychosomatic cold he's given her.<br /><br />First off, kudos to Stubby Kaye and B.S. Pulley as they reprise their Broadway roles as Nicely-Nicely Johnson and Benny Southstreet. There were never two more loveable gamblers than these guys.<br /><br />Brando is superb, as usual, and though he's not got the voice of Robert Alda or Peter Gallagher, you forget it-- as he has this sense of determination to bring all he can to his role as Sky Masterson. \"Luck Be A Lady\" gives me chills every time I see him perform the number. Especially enjoyable is hearing him say \"Daddy... I got cider in my ear.\"<br /><br />Simmons is charming and pleasant in a role well suited to her looks, voice and the way she carries herself. You long so dearly for her not only to win Sky (or, toward the end, believe him), but to help people overcome their gambling, drinking and other sins, and live a life with God. Her rendition of \"If I Were A Bell\" is splendid, to say the least!<br /><br />Sinatra is the man. He is so perfect for the role of Nathan Detroit-- and here he sings parts that Sam Levene from the Broadway cast never could (terrific actor, but the chap was tone deaf... go figure). I really enjoyed the addition of the song \"Adelaide\"... wish some guy would sing like that to ME. Frankie's cool, slick demeanor transcends the boundaries of this movie. But most importantly, you want him to marry Adelaide.<br /><br />And speaking of Adelaide, Vivian Blaine is just sheer perfection in this role. From the accent to her belting out \"Adelaide's Lament\", she's just terrific. And she's also my favorite part of the entire movie. She really makes you feel for Adelaide... especially when she cries right before and then again during \"Sue Me\". I still haven't decided whether I like \"Pet Me Poppa\" better than \"Bushel and a Peck\"... maybe I like them equally. Either way, she does fantastic with those as well as \"Take Back Your Mink.\" (I'm sad that they left out \"hollanderize\" from the film...) She's absolutely MARVELOUS, not to mention hilarious, and my favorite part of the entire film.<br /><br />One of the best things about this movie is their lingo. It's a mixture of high class and street slang. Never do they use \"It's\", \"I'll\" or \"That's.\" It's always \"It is\", \"I will\" and \"That is.\" Overall, Guys & Dolls is one of my favorite all time movies and musicals, and it's one that you should take time to watch every time it comes on. My only complaint? No \"Marry The Man Today.\" Now THAT'S a good song.    1\n",
      "{rant start} I didn't want to believe them at first, but I guess this is what people are talking about when they say South Korean cinema has peaked and may even be going downhill. After the surprisingly fun and moving monster movie \"Gwoemul\" (aka \"The Host\") of 2006-- which actually succeeded in making a sharp satire out of a B-movie genre-- successive Korean blockbusters have become more and more generic, even though their budgets (mainly spent on special effects) have become more and more fantastic. Do South Korean movie-makers really want to squander all the audience and investor goodwill, which their industry has built up since the 1999 break-out film \"Shiri/Swiri\", by making a whole series of big budget mediocre movies like mainland China did? {rant end}<br /><br />The only \"reason\" I can fathom for making this movie is to dupe the investors into financing the most detailed and fluid digital animation of a Korean/ East Asian-styled dragon I have seen to date, for the final scenes. Now if they had introduced that dragon at the beginning and given it more personality and purpose like in the 1996 \"Dragonheart\", the movie might have had a few more redeeming qualities other than having lots of digitally animated dragons. Remember \"Dungeons & Dragons\" in 2000? Hasn't anyone learnt that the trick is not how MUCH special effects you use, but how WELL you use it? I hope there are more (and better) Korean legends they can use, because they have just killed a lot of international interest in Korean dragon legends with the way they filmed this one.<br /><br />In short, I agree with all the negative reviews gone before and wonder how Koreans felt about having their folk anthem \"Arirang\" being played at the very end. As a creature feature, I would have given it at least 5 stars out of 10 if the special effects or action sequences had been worth it, but I've seen many video games with better camera work and scripting (just less dragons).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              1\n",
      "~~I was able to see this movie yesterday morning on a early viewing pass~~<br /><br />I am a mom of 2 children, who range from 11 down to 6. So I'm sure plenty of parents can relate to having to see many many \"kids\" movies. This was refreshing for me. I haven't read this particular book, so I don't know if it stayed true to the book or not. But it sure took the grossness factor to a high level. This is the story of the \"new\" kid in town and it just so happens that there are a group of boys who have formed a club of sorts and love to pick on kids ....sound familiar? Haven't we all suffered this one time or another. He has the little brother who he cant stand and parents that he is embarrassed about. What I enjoyed most of all was seeing how each character was totally different from another they all stood out. The bully (why do they always make the bully a red head? My daughter has red hair! and she is no bully!..lol) is well a great bully, who finds himself being yelled at by his own big brother. It took twists and turns and well you fall in love with all of them and really find yourself routing for all the characters! Even the parents, great connection between father and son. All around enjoyable, sweet,funny, gross etc......Take your kids!!! You will enjoy it as much as they do!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1\n",
      "    Film auteur Stephan Woloszczuk explores the depths of love, passion, and brotherhood and the devastating results of loss in his latest film BLINDSPOT.<br /><br />BLINDSPOT'S diegetic world is exploding with suspense and takes the audience on a twisting  journey to the core of the human soul.  As a director, he manages to draw the human spirit from the performances of his actors.   With superb editing, especially in the flashback scenes and beautiful cinematography, BLINDSPOT is a thought provoking suspense from beginning to end.  A thriller which leaves much to the minds' eye.<br /><br />What an  astounding accomplishment for Stephan Woloszczuk.<br /><br />  Cheers Stephan! Angela Sander                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           1\n",
      "ý thýnk uzak ýs the one of the best films of all times and everybody must realize this movie.I m a Turkish boy and a big cinema fun. and in this days our cinema industry is highing up.And UZAK is the best Turkish film of last ten years.and maybe one of the best films of all times.director nuri bilge ceylan is quite amazing.telling story,characters,atmosphere is wonderful.he is a minimalist director and tells about routine event family,dreams,expects,life.tells about you ,tells about me,tells about us.I promise you will find a piece of your body in this movie.cinema life welcomes a new director.he is waiting to realize.I promise yo you will love this movie please watch it                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1\n",
      "Name: sentiment, Length: 49582, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('review')['sentiment'].nunique())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "49995    False\n",
       "49996    False\n",
       "49997    False\n",
       "49998    False\n",
       "49999    False\n",
       "Length: 50000, dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated()    #remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loved today's show!!! It was a variety and not solely cooking (which would have been great too). Very stimulating and captivating, always keeping the viewer peeking around the corner to see what was coming up next. She is as down to earth and as personable as you get, like one of us which made the show all the more enjoyable. Special guests, who are friends as well made for a nice surprise too. Loved the 'first' theme and that the audience was invited to play along too. I must admit I was shocked to see her come in under her time limits on a few things, but she did it and by golly I'll be writing those recipes down. Saving time in the kitchen means more time with family. Those who haven't tuned in yet, find out what channel and the time, I assure you that you won't be disappointed.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      5\n",
      "Hilarious, clean, light-hearted, and quote-worthy. What else can you ask for in a film? This is my all-time, number one favorite movie. Ever since I was a little girl, I've dreamed of owning a blue van with flames and an observation bubble.<br /><br />The cliché characters in ridiculous situations are what make this film such great fun. The wonderful comedic chemistry between Stephen Furst (Harold) and Andy Tennant (Melio) make up most of my favorite parts of the movie. And who didn't love the hopeless awkwardness of Flynch? Don't forget the airport antics of Leon's cronies, dressed up as Hari Krishnas: dancing, chanting and playing the tambourine--unbeatable! The clues are genius, the locations are classic, and the plot is timeless.<br /><br />A word to the wise, if you didn't watch this film when you were little, it probably won't win a place in your heart today. But nevertheless give it a chance, you may find that \"It doesn't matter what you say, it doesn't matter what you do, you've gotta play.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        4\n",
      "This show comes up with interesting locations as fast as the travel channel. It is billed as reality but in actuality it is pure prime time soap opera. It's tries to use exotic locales as a facade to bring people into a phony contest & then proceeds to hook viewers on the contestants soap opera style.<br /><br />It also borrows from an early CBS game show pioneer- Beat The Clock- by inventing situations for its contestants to try & overcome. Then it rewards the winner money. If they can spice it up with a little interaction between the characters, even better. While the game format is in slow motion versus Beat The Clock- the real accomplishment of this series is to escape reality. <br /><br />This show has elements of several types of successful past programs. Reality television, hardly, but if your hooked on the contestants, locale or contest, this is your cup of tea. If your not, this entire series is as I say, drivel dripping with gravy. It is another show hiding behind the reality label which is the trend it started in 2000.<br /><br />It is slick & well produced, so it might last a while yet. After all, so do re-runs of Gilligan's Island, Green Acres, The Beverly Hillbillies & The Brady Bunch. This just doesn't employ professional actors. The intelligence level is about the same.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    3\n",
      "I see that C. Thomas Howell has appeared in many movies since his heyday in the 80s as an accomplished young actor.<br /><br />I bought this DVD because it was cheap and in part for the internet-related plot and to see how much older C. Thomas Howell is; I do not recall seeing him in any movies since the 1980s.<br /><br />In just a few words: what a very big disappointment. I give some low budget movies a chance, but this one started out lame. Within the first 15 minutes of the movie, this elusive woman is chatting with an Asian guy in a chatroom. They basically stimulate themselves to their own chat, she then insists on meeting the participant in person. She meets him, has sex, ties him up and then murders him in cold blood. The plot then deteriorates further.<br /><br />The plot is thin and flimsy and the acting is very stiff. Do not bother renting it much less purchasing it, even if it is in the $1 DVD bin. I plan to take my copy of the DVD to Goodwill. I am truly amazed that any of the prior reviewers here gave this movie a bad rating.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               3\n",
      "When i got this movie free from my job, along with three other similar movies.. I watched then with very low expectations. Now this movie isn't bad per se. You get what you pay for. It is a tale of love, betrayal, lies, sex, scandal, everything you want in a movie. Definitely not a Hollywood blockbuster, but for cheap thrills it is not that bad. I would probably never watch this movie again. In a nutshell this is the kind of movie that you would see either very late at night on a local television station that is just wanting to take up some time, or you would see it on a Sunday afternoon on a local television station that is trying to take up some time. Despite the bad acting, cliché lines, and sub par camera work. I didn't have the desire to turn off the movie and pretend like it never popped into my DVD player. The story has been done many times in many movies. This one is no different, no better, no worse. <br /><br />Just your average movie.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               3\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ..\n",
      "What horrible writing and acting. No personality. What, you can't make a good movie with a single character? Hmm, it was done in Castaway with self dialog.<br /><br />So this kid goes on a trip to see his father. The kid, Jason, takes a plane and the pilot has a heart attack and dies mid-flight. So the kid crashes in a lake and survives. Then he runs around, surviving in the wilderness until he gets rescued.<br /><br />During that time he fights a bear twice. The first time he fights it off in the lake. The second time he makes a spear out of a branch and spears the bear. Two shots of fake blood spurting out of the bear's chest reminded me of Monty Python's \"The Holy Grail\".<br /><br />Also the kid decides to kick a porcupine with predictable results.<br /><br />Gag.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     1\n",
      "There wasn't a 0 in the voting option so i was compelled to use the next available figure.<br /><br />It is a sad day for bollywood when such type of movies which have star-cast actors is nothing more are than a bunch of juvenile acting, and an awful script.<br /><br />This movie is nowhere near to be called a clone of Hitch. Salman khan with his usual take-off-you-shirt theme and Govinda with his in-humorous laughs. If somebody had told 2 decades ago that I would be writing a comment on Salman (after his success with Maine Pyar Kiya), I would have written him/her off.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               1\n",
      "This review has been written by someone who has read it (several times) and knows what they are talking about!. Firstly I have read others comments and noticed that some of the objections were really quite stupid. People who have read the book and other Jane Austens or for that matter any good book, will know that sticking to the book is vital you have to trust an author with what they do. If the viewer does not like it BECAUSE it sticks to the book well it shows they do not understand Jane Austen and obviously are not a true fan.<br /><br />Firstly if the viewer truly loved the book or Jane Austen in general, watching it for four hours should not prove difficult. Secondly, their society did care a lot for looks and so big, fancy hair styles would show off how rich you were, which in their day was a key factor for getting along in \"good\" society. I have to confess the female costumes were not brilliant but there were only a few bad ones and the males made up for it, also this prejudice for the Naval men not in their uniform is in nice words very silly!, today people do not go out with their uniform away from school or work because they have casual clothes and it was just the same in the 19th century. Also as it goes the acting is very good, it is subtle because that is how Jayne Austen writes! and the scene at the end is beautiful. You can not compare the filming to that of the 1995 version as technology has improved so much since them it is ridiculous to compare them in that. The actress who plays Ann is too old but her air of acting and how she does it makes up for it.<br /><br />People seem to prefer the 1995 version for some reason that I can not comprehend!. It does not stick to the book at all and so is flat, the ending is sentimental, they change major scenes, the only good actors are the leads and they I give you did a good job for what was given to them. Obviously the people who really, really like it are (I am sorry) stupid as they do not understand Persuasion and so need it to be overdone. The 1971 version is beautiful, romantic, was written by an excellent script writer (same who did Inspector Morse), had very good actors and really it is a film you can watch many times and during each you can be delighted with it.    1\n",
      "The Last Command (1928) is a silent film directed by Josef von Sternberg.It shows us Czarist General, Grand Duke Sergius Alexander (Emil Jannings) in his days of glory.In 1917 he had all the power but after the revolution and the collapse of Imperial Russia he has nothing.He also had the love of a woman, Natalie Dabrova (Evelyn Brent).About ten years later he applies for a small part in a film about the revolution.His old enemy Lev Andreyev (William Powell) is the director who gets to choose whether to hire him as a film extra or not.The Last Command is very good silent drama.Emil Jannings does memorable role work in the lead.Evelyn Brent is wonderful playing the woman lead.William Powell is great as always.There are plenty of scenes to remember in this movie.Like many scenes with Jannings and Brent.And then there is the ending with Powell and Jannings.This is a movie that touches in many parts.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  1\n",
      "It is a great movie if you have ever named your cars or are really into old, fast, or exotic cars. It has a plot and a lot of action. The car scenes are great except for the totally fake car jump scene. All of the other scenes are great. I really enjoyed it and I hope everyone else does as well.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      1\n",
      "Name: review, Length: 49582, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.review.value_counts())    #remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset={'review','sentiment'}, keep='first', inplace=True, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 49582 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     49582 non-null  object\n",
      " 1   sentiment  49582 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  response\n",
       "0  One of the other reviewers has mentioned that ...  positive         1\n",
       "1  A wonderful little production. <br /><br />The...  positive         1\n",
       "2  I thought this was a wonderful way to spend ti...  positive         1\n",
       "3  Basically there's a family where a little boy ...  negative         0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive         1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating another column, with column name as response positive ---> 1 and negative ---> 0 \n",
    "df['response'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 3 elements, new values have 2 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-bcdae3285a7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'review'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sentiment'\u001b[0m\u001b[1;33m]\u001b[0m    \u001b[1;31m#remove\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda-Python\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5285\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5286\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5287\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5288\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5289\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda-Python\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 661\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    662\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda-Python\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    178\u001b[0m                 \u001b[1;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[1;34mf\"values have {new_len} elements\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 3 elements, new values have 2 elements"
     ]
    }
   ],
   "source": [
    "df.columns = ['review','sentiment']    #remove\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# firstly dropping sentiment column and then rename response column to sentiment\n",
    "del df['sentiment']\n",
    "df=df.rename(columns = {'response':'sentiment'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical value converted to Numerical value\n",
    "1. Sentiment column value changed from categorical to numerical\n",
    "2. Positive value converted to 1 and negative value converted to 0\n",
    "3. Initially storing the value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Text pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clear all html tags\n",
    "def clearHtml(sentence):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleanText = re.sub(cleanr,' ',sentence)\n",
    "    return cleanText       # output is in string\n",
    "# Function to clear all extra symbols except single quote\n",
    "def clearPunc(sentence):\n",
    "#     cleaned = re.sub(r'[?|!\\|\"|#|.|,|)|(\\||\\\\|/|:]',r' ',sentence)\n",
    "    cleaned = re.sub('[^A-Za-z0-9\\']+', ' ', sentence)\n",
    "    return cleaned        # output is in string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert common contractions to Normal words\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove all other single quotes after treating common contraction\n",
    "def clearRestSingleQuotes(sentence):\n",
    "    cleaned = re.sub('[^A-Za-z0-9]+', ' ', sentence)\n",
    "    return cleaned  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200456\n"
     ]
    }
   ],
   "source": [
    "# remove\n",
    "count_tag=0\n",
    "for sent in range(len(df['review'].values)):\n",
    "    list_of_tag = re.findall('<.*?>',df['review'].values[sent])\n",
    "    count_tag+=len(list_of_tag)\n",
    "print(count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'above', 'which', 'their', 'not', 'our', 'or', 'all', 'doing', 'as', 'hadn', 'had', 'ours', 'him', 'who', 'because', 'out', 'hasn', 'has', 'why', 'then', 'ourselves', 'any', 'very', \"aren't\", 'if', 'isn', 'shouldn', 'now', 'only', 'over', 's', \"don't\", \"she's\", 'before', 'can', 'such', 'this', 'during', 'weren', \"weren't\", 'down', 'of', 'aren', \"you'd\", 'they', 'didn', \"that'll\", 'we', 'll', 'at', 'haven', 'there', 'into', 'won', 'she', \"mightn't\", 've', 'her', 'after', \"mustn't\", 'between', 'mustn', \"hadn't\", 'below', \"wouldn't\", 'in', 'but', 'when', 'other', 'off', 'for', 'don', 'with', 'once', 'i', 'here', 'few', 'yourselves', 'an', 'from', 'wouldn', 'just', 'be', \"should've\", 'me', 'have', 'was', 'will', 'theirs', \"didn't\", 'itself', \"won't\", 'he', 'having', 'to', \"needn't\", 'under', \"wasn't\", 'hers', 'most', \"isn't\", 'been', 'being', 't', 'yourself', 'while', 'same', 'up', 'more', \"you've\", 'ain', 'the', 'my', 'until', \"you'll\", \"doesn't\", 'yours', 'how', 'do', 'couldn', \"it's\", 'against', \"couldn't\", 'no', 'both', 'needn', 'its', 'nor', 'herself', 'shan', 'is', 'you', 'these', 'those', 'again', 'are', 'o', 'that', 'should', 'own', 'what', 'mightn', 'does', 'a', 'your', 'on', 'ma', 'were', 'his', \"you're\", 'whom', 'than', \"hasn't\", 'themselves', 'y', 'it', 'did', 'too', 'through', 'about', \"shouldn't\", 'by', 'where', \"shan't\", 'so', 'm', 'myself', \"haven't\", 'am', 'each', 're', 'doesn', 'some', 'and', 'd', 'himself', 'them', 'wasn', 'further'}\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "quantat\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "quant\n"
     ]
    }
   ],
   "source": [
    "# partially remove\n",
    "stop_words =set(stopwords.words('english'))    # set of stopwords\n",
    "sno = nltk.stem.SnowballStemmer('english')\n",
    "ps = PorterStemmer()\n",
    "print(stop_words)\n",
    "print('-'*125)\n",
    "print(sno.stem('quantative'))\n",
    "print('-'*125)\n",
    "print(ps.stem('quantative'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-0d909814b3ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#remove\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msample_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'review'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msample_text\u001b[0m      \u001b[1;31m# output is in Array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#remove\n",
    "sample_text = dataset['review'].values[1]\n",
    "sample_text      # output is in Array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-987d5bbb8ed0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#remove\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msample_text\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mclearHtml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msample_text\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mclearPunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msample_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sample_text' is not defined"
     ]
    }
   ],
   "source": [
    "#remove\n",
    "sample_text= clearHtml(sample_text)\n",
    "sample_text= clearPunc(sample_text)\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-1e3c6fae0f87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# remove\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msample_text2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'review'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msample_text2\u001b[0m     \u001b[1;31m# output is in Array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# remove\n",
    "sample_text2 = dataset['review'].values[2]\n",
    "sample_text2     # output is in Array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-1c1fafba75ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# remove\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msample_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecontracted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msample_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sample_text' is not defined"
     ]
    }
   ],
   "source": [
    "# remove\n",
    "sample_text = decontracted(sample_text)\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-dda18d1ed6b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#remove\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msample_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclearRestSingleQuotes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msample_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sample_text' is not defined"
     ]
    }
   ],
   "source": [
    "#remove\n",
    "sample_text = clearRestSingleQuotes(sample_text)\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_text is ready now "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8980     0\n",
       "35912    0\n",
       "47554    0\n",
       "10799    1\n",
       "38610    0\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()   #remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of row of training dataset review: 34707\n",
      "no of row of training dataset sentiment: 34707\n"
     ]
    }
   ],
   "source": [
    "print('no of row of training dataset review:',len(x_train))\n",
    "print('no of row of training dataset sentiment:',len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of row of test dataset review: 14875\n",
      "no of row of test dataset sentiment: 14875\n"
     ]
    }
   ],
   "source": [
    "print('no of row of test dataset review:',len(x_test))\n",
    "print('no of row of test dataset sentiment:',len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8980     The Blob starts with one of the most bizarre t...\n",
       "35912    I don't know what it was about this film that ...\n",
       "47554    I'd heard about this movie a while ago from a ...\n",
       "10799    I loved this movie from beginning to end.I am ...\n",
       "38610    Not even 'lesser' Hitch, but simply a bad movi...\n",
       "19307    What an insult to the SA film industry! I have...\n",
       "14227    The Treasure Island DVD should be required vie...\n",
       "8251     The 1998 version of \"Psycho\" needed to be set ...\n",
       "48666    When \"The Net\" was first being advertised, the...\n",
       "44247    I've read every book to date in the left behin...\n",
       "48081    This movie is excellent!Angel is beautiful and...\n",
       "10798    There should be a rule that states quite clear...\n",
       "15332    This scary and rather gory adaptation of Steph...\n",
       "16630    And I'm serious! Truly one of the most fantast...\n",
       "24900    Not that I dislike childrens movies, but this ...\n",
       "44542    I happened upon a rare copy of this early Almo...\n",
       "49903    This is one of the most hateful and cruel movi...\n",
       "37494    i have one word: focus.<br /><br />well.<br />...\n",
       "39891    This film is awful. The CGI is the very cheap ...\n",
       "49738    A badly-acted two-character comedy-drama abrup...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head(20)     #remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73f5c2c98904945be84dfd25e273334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34707.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "i=0\n",
    "lemmatizer_word = WordNetLemmatizer() \n",
    "x_train_pre_processed = []\n",
    "all_positive_word_train = []\n",
    "all_negative_words_train = []\n",
    "for sent in tqdm(x_train.values):\n",
    "    filtered_sentence=[]\n",
    "#     print(sent)\n",
    "    sent = clearHtml(sent)\n",
    "    sent=  clearPunc(sent)\n",
    "    sent = decontracted(sent)\n",
    "    sent = clearRestSingleQuotes(sent)\n",
    "    for words in sent.split():\n",
    "        for clear_words in clearPunc(words).split():\n",
    "            if ((clear_words.isalpha())) & (len(clear_words)>2):\n",
    "                if (clear_words.lower() not in stop_words):\n",
    "#                     s = (ps.stem(clear_words.lower())).encode('utf8')      #PorterStemmer\n",
    "#                     s = (sno.stem(clear_words.lower())).encode('utf8')      #Snowball Stemmer\n",
    "                      s = (lemmatizer_word.lemmatize(clear_words.lower())).encode('utf8')      # Lemmantizer\n",
    "                      filtered_sentence.append(s)\n",
    "                      if (y_train.values)[i]:\n",
    "                            all_positive_word_train.append(s)\n",
    "                      else:\n",
    "                            all_negative_words_train.append(s)\n",
    "        str = b\" \".join(filtered_sentence)\n",
    "#     print(str)\n",
    "#     print('-'*90)\n",
    "    x_train_pre_processed.append(str)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'know film made react viscerally perhaps character unlikable compelling enough care perhaps disorganized storyline perhaps fact rob lowe wore long dangly earring eyeliner perhaps point movie break song perhaps never perhaps everything garish hyperbole perhaps character pump fist driving away camera fade know made hate mean trying watch willing find'\n",
      "------------------------------------------------------------------------------------------\n",
      "[b'loved', b'movie', b'beginning', b'end', b'musician', b'let', b'drug', b'get', b'way', b'thing']\n",
      "------------------------------------------------------------------------------------------\n",
      "Most positive words [(b'film', 34495), (b'movie', 31163), (b'one', 19737), (b'like', 12607), (b'time', 11215), (b'good', 10515), (b'story', 9798), (b'character', 9720), (b'would', 9093), (b'great', 9083), (b'see', 8876), (b'well', 8847), (b'get', 7777), (b'make', 7718), (b'also', 7581), (b'really', 7387), (b'scene', 7084), (b'life', 6948), (b'show', 6711), (b'even', 6633)]\n",
      "------------------------------------------------------------------------------------------\n",
      "[b'blob', b'start', b'one', b'bizarre', b'theme', b'song', b'ever', b'sung', b'uncredited', b'burt']\n",
      "------------------------------------------------------------------------------------------\n",
      "Most negative words [(b'movie', 40711), (b'film', 30303), (b'one', 18934), (b'like', 15796), (b'would', 12499), (b'even', 10652), (b'time', 10430), (b'good', 10297), (b'bad', 10255), (b'character', 9898), (b'get', 9343), (b'make', 9000), (b'really', 8429), (b'scene', 8032), (b'could', 7926), (b'see', 7759), (b'story', 7621), (b'much', 7038), (b'people', 6617), (b'thing', 6522)]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_pre_processed[1])\n",
    "print('-'*90) \n",
    "print(all_positive_word_train[0:10])\n",
    "print('-'*90)\n",
    "freq_dist_positive =nltk.FreqDist(all_positive_word_train)\n",
    "print('Most positive words',freq_dist_positive.most_common(20))\n",
    "print('-'*90)\n",
    "print(all_negative_words_train[0:10])\n",
    "print('-'*90)\n",
    "freq_dist_negative =nltk.FreqDist(all_negative_words_train)\n",
    "print('Most negative words',freq_dist_negative.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- Few words are there in negative and positive both like 'good', which actually positive word in real life scenario so it might be chances that it used with not and not is removed in stopwords.\n",
    "- To prevent that I am removing not from set of stopwords and re-run the code to check whether my observation is correct or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "#removing stop words like \"not\" should be avoided before building n-grams\n",
    "\n",
    "print(len(stop_words))\n",
    "stop_words.remove('not')       #removing not words from stop words\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86874af7917e480693231c9e78eea825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34707.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "i=0\n",
    "lemmatizer_word = WordNetLemmatizer() \n",
    "x_train_pre_processed = []\n",
    "all_positive_word_train = []\n",
    "all_negative_words_train = []\n",
    "for sent in tqdm(x_train.values):\n",
    "    filtered_sentence=[]\n",
    "#     print(sent)\n",
    "    sent = clearHtml(sent)\n",
    "    sent=  clearPunc(sent)\n",
    "    sent = decontracted(sent)\n",
    "    sent = clearRestSingleQuotes(sent)\n",
    "    for words in sent.split():\n",
    "        for clear_words in clearPunc(words).split():\n",
    "            if ((clear_words.isalpha())) & (len(clear_words)>2):\n",
    "                if (clear_words.lower() not in stop_words):\n",
    "#                     s = (ps.stem(clear_words.lower())).encode('utf8')      #PorterStemmer\n",
    "#                     s = (sno.stem(clear_words.lower())).encode('utf8')      #Snowball Stemmer\n",
    "                      s = (lemmatizer_word.lemmatize(clear_words.lower())).encode('utf8')      # Lemmantizer\n",
    "                      filtered_sentence.append(s)\n",
    "                      if (y_train.values)[i]:\n",
    "                            all_positive_word_train.append(s)\n",
    "                      else:\n",
    "                            all_negative_words_train.append(s)\n",
    "        str = b\" \".join(filtered_sentence)\n",
    "#     print(str)\n",
    "#     print('-'*90)\n",
    "    x_train_pre_processed.append(str)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'not know film made react viscerally perhaps character unlikable not compelling enough care perhaps disorganized storyline perhaps fact rob lowe wore long dangly earring eyeliner perhaps point movie break song perhaps never perhaps everything garish hyperbole perhaps character pump fist driving away camera fade not know made hate mean trying watch not willing find'\n",
      "------------------------------------------------------------------------------------------\n",
      "[b'loved', b'movie', b'beginning', b'end', b'musician', b'let', b'drug', b'get', b'way', b'thing']\n",
      "------------------------------------------------------------------------------------------\n",
      "Most positive words [(b'not', 38169), (b'film', 34495), (b'movie', 31163), (b'one', 19737), (b'like', 12607), (b'time', 11215), (b'good', 10515), (b'story', 9798), (b'character', 9720), (b'would', 9093), (b'great', 9083), (b'see', 8876), (b'well', 8847), (b'get', 7777), (b'make', 7718), (b'also', 7581), (b'really', 7387), (b'scene', 7084), (b'life', 6948), (b'show', 6711)]\n",
      "------------------------------------------------------------------------------------------\n",
      "[b'blob', b'start', b'one', b'bizarre', b'theme', b'song', b'ever', b'sung', b'uncredited', b'burt']\n",
      "------------------------------------------------------------------------------------------\n",
      "Most negative words [(b'not', 50031), (b'movie', 40711), (b'film', 30303), (b'one', 18934), (b'like', 15796), (b'would', 12499), (b'even', 10652), (b'time', 10430), (b'good', 10297), (b'bad', 10255), (b'character', 9898), (b'get', 9343), (b'make', 9000), (b'really', 8429), (b'scene', 8032), (b'could', 7926), (b'see', 7759), (b'story', 7621), (b'much', 7038), (b'people', 6617)]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_pre_processed[1])\n",
    "print('-'*90) \n",
    "print(all_positive_word_train[0:10])\n",
    "print('-'*90)\n",
    "freq_dist_positive =nltk.FreqDist(all_positive_word_train)\n",
    "print('Most positive words',freq_dist_positive.most_common(20))\n",
    "print('-'*90)\n",
    "print(all_negative_words_train[0:10])\n",
    "print('-'*90)\n",
    "freq_dist_negative =nltk.FreqDist(all_negative_words_train)\n",
    "print('Most negative words',freq_dist_negative.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- So our early observation was correct not appear 50031 times in negative words so it might be appear as not good or not like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc696d057c5448eb028f66cabff42cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14875.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "i=0\n",
    "lemmatizer_word = WordNetLemmatizer() \n",
    "x_test_pre_processed = []\n",
    "all_positive_words_test = []\n",
    "all_negative_words_test = []\n",
    "for sent in tqdm(x_test.values):\n",
    "    filtered_sentence=[]\n",
    "#     print(sent)\n",
    "    sent = clearHtml(sent)\n",
    "    sent=  clearPunc(sent)\n",
    "    sent = decontracted(sent)\n",
    "    sent = clearRestSingleQuotes(sent)\n",
    "    for words in sent.split():\n",
    "        for clear_words in clearPunc(words).split():\n",
    "            if ((clear_words.isalpha())) & (len(clear_words)>2):\n",
    "                if (clear_words.lower() not in stop_words):\n",
    "#                     s = (ps.stem(clear_words.lower())).encode('utf8')      #PorterStemmer\n",
    "#                     s = (sno.stem(clear_words.lower())).encode('utf8')      #Snowball Stemmer\n",
    "                      s = (lemmatizer_word.lemmatize(clear_words.lower())).encode('utf8')      # Lemmantizer\n",
    "                      filtered_sentence.append(s)\n",
    "                      if (y_test.values)[i]:\n",
    "                            all_positive_words_test.append(s)\n",
    "                      else:\n",
    "                            all_negative_words_test.append(s)\n",
    "        str = b\" \".join(filtered_sentence)\n",
    "#     print(str)\n",
    "#     print('-'*90)\n",
    "    x_test_pre_processed.append(str)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'guest future tell fascinating story time travel friendship battle good evil small budget child actor special effect something spielberg lucas learn sixth grader kolya nick gerasimov find time machine basement decrepit building travel year future discovers near perfect utopian society robot play guitar write poetry everyone kind people enjoy everything technology offer alice daughter prominent scientist invented device called mielophone allows read mind human animal device put good bad use depending whose hand fall two evil space pirate saturn want rule universe attempt steal mielophone fall hand century school boy nick pirate hot track travel back time followed pirate alice chaos confusion funny situation follow luckless pirate try blend earthling alice enrolls school nick go demonstrates superhuman ability class catch alice not know nick look like pirate also pirate able change appearance turn literally anyone hmm wonder james cameron got idea terminator get nick mielophone first excellent plot non stop adventure great soundtrack wish hollywood made kid movie like one'\n",
      "------------------------------------------------------------------------------------------\n",
      "[b'guest', b'future', b'tell', b'fascinating', b'story', b'time', b'travel', b'friendship', b'battle', b'good']\n",
      "------------------------------------------------------------------------------------------\n",
      "Most positive words [(b'not', 16472), (b'film', 15056), (b'movie', 13469), (b'one', 8437), (b'like', 5522), (b'time', 5035), (b'good', 4520), (b'story', 4344), (b'character', 4245), (b'would', 4030), (b'see', 3998), (b'well', 3939), (b'great', 3854), (b'make', 3475), (b'get', 3372), (b'really', 3316), (b'also', 3180), (b'even', 2940), (b'scene', 2938), (b'life', 2914)]\n",
      "------------------------------------------------------------------------------------------\n",
      "[b'soul', b'plane', b'horrible', b'attempt', b'comedy', b'appeal', b'people', b'thick', b'skull', b'bloodshot']\n",
      "------------------------------------------------------------------------------------------\n",
      "Most negative words [(b'not', 21256), (b'movie', 17116), (b'film', 12963), (b'one', 7929), (b'like', 6863), (b'would', 5287), (b'time', 4519), (b'even', 4444), (b'good', 4330), (b'bad', 4308), (b'character', 4263), (b'get', 3973), (b'make', 3845), (b'really', 3785), (b'story', 3334), (b'could', 3317), (b'scene', 3241), (b'see', 3220), (b'much', 2938), (b'thing', 2840)]\n"
     ]
    }
   ],
   "source": [
    "print(x_test_pre_processed[1])\n",
    "print('-'*90) \n",
    "print(all_positive_words_test[0:10])\n",
    "print('-'*90)\n",
    "freq_dist_positive =nltk.FreqDist(all_positive_words_test)\n",
    "print('Most positive words',freq_dist_positive.most_common(20))\n",
    "print('-'*90)\n",
    "print(all_negative_words_test[0:10])\n",
    "print('-'*90)\n",
    "freq_dist_negative =nltk.FreqDist(all_negative_words_test)\n",
    "print('Most negative words',freq_dist_negative.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_pre_processed) #remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove\n",
    "# from openpyxl import Workbook\n",
    "wb = Workbook()\n",
    "\n",
    "# grab the active worksheet\n",
    "ws = wb.active\n",
    "\n",
    "# Data can be assigned directly to cells\n",
    "i = 1\n",
    "for i in range(len(pre_processed_string)):\n",
    "    ws['A{}'.format(i+1)] = pre_processed_string[i]\n",
    "\n",
    "# Save the file\n",
    "wb.save(\"clean_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 4, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-213-247c5bc54d4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'clean_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda-Python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda-Python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda-Python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda-Python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2035\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2036\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2037\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2038\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 4, saw 2\n"
     ]
    }
   ],
   "source": [
    "#remove\n",
    "df = pd.read_csv('clean_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34707, 2218175)\n",
      "(14875, 2218175)\n"
     ]
    }
   ],
   "source": [
    "# creating BOW wit bigram\n",
    "count_vect = CountVectorizer(ngram_range=(1,2))\n",
    "x_train_count = count_vect.fit_transform(x_train_pre_processed)\n",
    "x_test_count = count_vect.transform(x_test_pre_processed)\n",
    "print(x_train_count.get_shape())\n",
    "print(x_test_count.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34707, 2218175)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove\n",
    "count_vect = CountVectorizer(ngram_range=(1,2))\n",
    "x_train_count = count_vect.fit_transform(X_train_pre_processed)\n",
    "x_train_count.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14875, 1116928)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove\n",
    "count_vect_test = CountVectorizer(ngram_range=(1,2))\n",
    "x_test_count = count_vect_test.fit_transform(X_test_pre_processed)\n",
    "x_test_count.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaa',\n",
       " 'aaa ball',\n",
       " 'aaa even',\n",
       " 'aaa favorite',\n",
       " 'aaa jawani',\n",
       " 'aaa level',\n",
       " 'aaa not',\n",
       " 'aaa yeah',\n",
       " 'aaaaaaaaaaaahhhhhhhhhhhhhh',\n",
       " 'aaaaaaaaaaaahhhhhhhhhhhhhh hurting',\n",
       " 'aaaaaaaargh',\n",
       " 'aaaaaaah',\n",
       " 'aaaaaaah saw',\n",
       " 'aaaaaaahhhhhhggg',\n",
       " 'aaaaagh',\n",
       " 'aaaaagh scene',\n",
       " 'aaaaah',\n",
       " 'aaaaah movie',\n",
       " 'aaaaah never',\n",
       " 'aaaaahhhh',\n",
       " 'aaaaahhhh get',\n",
       " 'aaaaatch',\n",
       " 'aaaaatch kah',\n",
       " 'aaaaaw',\n",
       " 'aaaaaw cry',\n",
       " 'aaaahhhhhh',\n",
       " 'aaaahhhhhh terrible',\n",
       " 'aaaahhhhhhh',\n",
       " 'aaaahhhhhhh run',\n",
       " 'aaaarrgh',\n",
       " 'aaaarrgh former',\n",
       " 'aaaawwwwww',\n",
       " 'aaaawwwwww well',\n",
       " 'aaaggghhhhhhh',\n",
       " 'aaaggghhhhhhh not',\n",
       " 'aaah',\n",
       " 'aaah friggin',\n",
       " 'aaah leg',\n",
       " 'aaahhhhhhh',\n",
       " 'aaahhhhhhh scene',\n",
       " 'aaall',\n",
       " 'aaall way',\n",
       " 'aaam',\n",
       " 'aaam going',\n",
       " 'aaargh',\n",
       " 'aaargh bad',\n",
       " 'aaargh dead',\n",
       " 'aaargh not',\n",
       " 'aab',\n",
       " 'aab tak',\n",
       " 'aachen',\n",
       " 'aachen palm',\n",
       " 'aachen two',\n",
       " 'aada',\n",
       " 'aada adhura',\n",
       " 'aag',\n",
       " 'aag actually',\n",
       " 'aag break',\n",
       " 'aag director',\n",
       " 'aag fail',\n",
       " 'aag figure',\n",
       " 'aag fire',\n",
       " 'aag hit',\n",
       " 'aag jugnu',\n",
       " 'aag make',\n",
       " 'aag never',\n",
       " 'aag not',\n",
       " 'aag one',\n",
       " 'aag put',\n",
       " 'aag sholay',\n",
       " 'aag take',\n",
       " 'aag totally',\n",
       " 'aag worst',\n",
       " 'aag worth',\n",
       " 'aage',\n",
       " 'aage haugland',\n",
       " 'aage pardey',\n",
       " 'aaghh',\n",
       " 'aaghh bee',\n",
       " 'aah',\n",
       " 'aah come',\n",
       " 'aah yes',\n",
       " 'aahe',\n",
       " 'aahe parsha',\n",
       " 'aahed',\n",
       " 'aahed theron',\n",
       " 'aahhh',\n",
       " 'aahhhh',\n",
       " 'aahhhh bless',\n",
       " 'aaila',\n",
       " 'aaila brilliantly',\n",
       " 'aailiyah',\n",
       " 'aailiyah pretty',\n",
       " 'aaja',\n",
       " 'aaja nachle',\n",
       " 'aajala',\n",
       " 'aajala ayala',\n",
       " 'aak',\n",
       " 'aak gag',\n",
       " 'aakash',\n",
       " 'aakash kenya',\n",
       " 'aake',\n",
       " 'aake sandgren',\n",
       " 'aakrosh',\n",
       " 'aakrosh second',\n",
       " 'aaliyah',\n",
       " 'aaliyah absolutely',\n",
       " 'aaliyah actually',\n",
       " 'aaliyah although',\n",
       " 'aaliyah blow',\n",
       " 'aaliyah fan',\n",
       " 'aaliyah filming',\n",
       " 'aaliyah last',\n",
       " 'aaliyah lestat',\n",
       " 'aaliyah make',\n",
       " 'aaliyah nice',\n",
       " 'aaliyah one',\n",
       " 'aaliyah perfect',\n",
       " 'aaliyah played',\n",
       " 'aaliyah role',\n",
       " 'aaliyah sadly',\n",
       " 'aaliyah sexy',\n",
       " 'aaliyah simply',\n",
       " 'aaliyah unfortunately',\n",
       " 'aaliyah untimely',\n",
       " 'aaliyah vampire',\n",
       " 'aalox',\n",
       " 'aames',\n",
       " 'aames cruz',\n",
       " 'aames film',\n",
       " 'aames young',\n",
       " 'aamir',\n",
       " 'aamir acting',\n",
       " 'aamir face',\n",
       " 'aamir ghulam',\n",
       " 'aamir given',\n",
       " 'aamir khan',\n",
       " 'aamir playing',\n",
       " 'aamir prem',\n",
       " 'aamir salman',\n",
       " 'aamir steal',\n",
       " 'aamir still',\n",
       " 'aamir yet',\n",
       " 'aamto',\n",
       " 'aamto master',\n",
       " 'aan',\n",
       " 'aan men',\n",
       " 'aan pyasa',\n",
       " 'aankh',\n",
       " 'aankh give',\n",
       " 'aankhen',\n",
       " 'aankhen adapted',\n",
       " 'aankhen director',\n",
       " 'aankhen fails',\n",
       " 'aankhen manage',\n",
       " 'aankhen raja',\n",
       " 'aankhen remake',\n",
       " 'aaoon',\n",
       " 'aaoon fitting',\n",
       " 'aap',\n",
       " 'aap saroor',\n",
       " 'aap surror',\n",
       " 'aapke',\n",
       " 'aapke hain',\n",
       " 'aapkey',\n",
       " 'aapkey hain',\n",
       " 'aaran',\n",
       " 'aaran one',\n",
       " 'aardman',\n",
       " 'aardman animation',\n",
       " 'aardman character',\n",
       " 'aardman could',\n",
       " 'aardman creating',\n",
       " 'aardman duo',\n",
       " 'aardman dynamic',\n",
       " 'aardman film',\n",
       " 'aardman lazed',\n",
       " 'aardman masterpiece',\n",
       " 'aardman movie',\n",
       " 'aardman original',\n",
       " 'aardman released',\n",
       " 'aardman studio',\n",
       " 'aardman style',\n",
       " 'aardman team',\n",
       " 'aardman would',\n",
       " 'aardvark',\n",
       " 'aardvark dog',\n",
       " 'aardvark fighting',\n",
       " 'aardvark trying',\n",
       " 'aardvark unfortunately',\n",
       " 'aarf',\n",
       " 'aarf show',\n",
       " 'aargh',\n",
       " 'aargh gun',\n",
       " 'aargh let',\n",
       " 'aargh superman',\n",
       " 'aarika',\n",
       " 'aarika well',\n",
       " 'aaron',\n",
       " 'aaron advice',\n",
       " 'aaron altman',\n",
       " 'aaron anchor',\n",
       " 'aaron another',\n",
       " 'aaron back',\n",
       " 'aaron badly',\n",
       " 'aaron bank',\n",
       " 'aaron blood',\n",
       " 'aaron boone',\n",
       " 'aaron brook',\n",
       " 'aaron brought',\n",
       " 'aaron carter',\n",
       " 'aaron character',\n",
       " 'aaron christian',\n",
       " 'aaron cinematography',\n",
       " 'aaron concert',\n",
       " 'aaron cory',\n",
       " 'aaron cruel',\n",
       " 'aaron curb',\n",
       " 'aaron decent',\n",
       " 'aaron directed',\n",
       " 'aaron eckhardt',\n",
       " 'aaron eckhart',\n",
       " 'aaron escape',\n",
       " 'aaron fors',\n",
       " 'aaron garlin',\n",
       " 'aaron get',\n",
       " 'aaron getting',\n",
       " 'aaron give',\n",
       " 'aaron given',\n",
       " 'aaron great',\n",
       " 'aaron hotties',\n",
       " 'aaron killing',\n",
       " 'aaron knews',\n",
       " 'aaron known',\n",
       " 'aaron lustig',\n",
       " 'aaron mandel',\n",
       " 'aaron mental',\n",
       " 'aaron michael',\n",
       " 'aaron mind',\n",
       " 'aaron miraculously',\n",
       " 'aaron neville',\n",
       " 'aaron norris',\n",
       " 'aaron not',\n",
       " 'aaron oliver',\n",
       " 'aaron overall',\n",
       " 'aaron paul',\n",
       " 'aaron pearl',\n",
       " 'aaron pederson',\n",
       " 'aaron peirce',\n",
       " 'aaron picked',\n",
       " 'aaron platt',\n",
       " 'aaron real',\n",
       " 'aaron running',\n",
       " 'aaron russo',\n",
       " 'aaron scates',\n",
       " 'aaron schneider',\n",
       " 'aaron seen',\n",
       " 'aaron seltzer',\n",
       " 'aaron sheritt',\n",
       " 'aaron sherritt',\n",
       " 'aaron show',\n",
       " 'aaron shown',\n",
       " 'aaron sings',\n",
       " 'aaron sorkin',\n",
       " 'aaron spelling',\n",
       " 'aaron start',\n",
       " 'aaron steve',\n",
       " 'aaron sudden',\n",
       " 'aaron though',\n",
       " 'aaron trip',\n",
       " 'aaron unfathomable',\n",
       " 'aaron upbringing',\n",
       " 'aaron vanek',\n",
       " 'aaron wake',\n",
       " 'aaron whole',\n",
       " 'aaron wonderfully',\n",
       " 'aaron would',\n",
       " 'aaron yamasato',\n",
       " 'aarp',\n",
       " 'aarp card',\n",
       " 'aarrrgh',\n",
       " 'aarrrgh never',\n",
       " 'aashok',\n",
       " 'aashok make',\n",
       " 'aasman',\n",
       " 'aasman niche',\n",
       " 'aatish',\n",
       " 'aatish kapadia',\n",
       " 'aaton',\n",
       " 'aaton god',\n",
       " 'aau',\n",
       " 'aau chin',\n",
       " 'aauugghh',\n",
       " 'aauugghh god',\n",
       " 'aavjo',\n",
       " 'aavjo vhala',\n",
       " 'aawip',\n",
       " 'aawip fails',\n",
       " 'aawip screenplay',\n",
       " 'aawip try',\n",
       " 'ab',\n",
       " 'ab alexandra',\n",
       " 'ab awesome',\n",
       " 'ab cbn',\n",
       " 'ab fat',\n",
       " 'ab played',\n",
       " 'ab rich',\n",
       " 'aba',\n",
       " 'aba mastermind',\n",
       " 'aback',\n",
       " 'aback appearance',\n",
       " 'aback arab',\n",
       " 'aback babbage',\n",
       " 'aback change',\n",
       " 'aback criticized',\n",
       " 'aback ethic',\n",
       " 'aback little',\n",
       " 'aback much',\n",
       " 'aback realizes',\n",
       " 'aback recommend',\n",
       " 'aback shear',\n",
       " 'aback shrinking',\n",
       " 'aback story',\n",
       " 'aback worker',\n",
       " 'aback writing',\n",
       " 'abadi',\n",
       " 'abadi shayesteh',\n",
       " 'abahy',\n",
       " 'abahy turn',\n",
       " 'abanazer',\n",
       " 'abanazer church',\n",
       " 'abanazer lovely',\n",
       " 'abandon',\n",
       " 'abandon alien',\n",
       " 'abandon arm',\n",
       " 'abandon attempt',\n",
       " 'abandon bunch',\n",
       " 'abandon cannot',\n",
       " 'abandon car',\n",
       " 'abandon care',\n",
       " 'abandon claim',\n",
       " 'abandon clear',\n",
       " 'abandon concentrate',\n",
       " 'abandon consistency',\n",
       " 'abandon cornfield',\n",
       " 'abandon crystina',\n",
       " 'abandon dying',\n",
       " 'abandon effort',\n",
       " 'abandon episode',\n",
       " 'abandon every',\n",
       " 'abandon everything',\n",
       " 'abandon evil',\n",
       " 'abandon front',\n",
       " 'abandon get',\n",
       " 'abandon heretofore',\n",
       " 'abandon high',\n",
       " 'abandon hit',\n",
       " 'abandon hollywood',\n",
       " 'abandon hope',\n",
       " 'abandon house',\n",
       " 'abandon humanity',\n",
       " 'abandon husband',\n",
       " 'abandon hyde',\n",
       " 'abandon idea',\n",
       " 'abandon japanese',\n",
       " 'abandon kermit',\n",
       " 'abandon life',\n",
       " 'abandon logic',\n",
       " 'abandon look',\n",
       " 'abandon looking',\n",
       " 'abandon magic',\n",
       " 'abandon making',\n",
       " 'abandon management',\n",
       " 'abandon mansion',\n",
       " 'abandon marriage',\n",
       " 'abandon meet',\n",
       " 'abandon men',\n",
       " 'abandon mistress',\n",
       " 'abandon movie',\n",
       " 'abandon music',\n",
       " 'abandon mutual',\n",
       " 'abandon native',\n",
       " 'abandon not',\n",
       " 'abandon notable',\n",
       " 'abandon nuance',\n",
       " 'abandon order',\n",
       " 'abandon pay',\n",
       " 'abandon personal',\n",
       " 'abandon post',\n",
       " 'abandon pretense',\n",
       " 'abandon pretext',\n",
       " 'abandon principle',\n",
       " 'abandon real',\n",
       " 'abandon reggae',\n",
       " 'abandon responsibility',\n",
       " 'abandon rhonda',\n",
       " 'abandon role',\n",
       " 'abandon search',\n",
       " 'abandon second',\n",
       " 'abandon shop',\n",
       " 'abandon side',\n",
       " 'abandon silent',\n",
       " 'abandon silently',\n",
       " 'abandon slapstick',\n",
       " 'abandon tactic',\n",
       " 'abandon technology',\n",
       " 'abandon territory',\n",
       " 'abandon think',\n",
       " 'abandon tuning',\n",
       " 'abandon viru',\n",
       " 'abandon want',\n",
       " 'abandon well',\n",
       " 'abandon within',\n",
       " 'abandon wounded',\n",
       " 'abandon young',\n",
       " 'abandoned',\n",
       " 'abandoned aerial',\n",
       " 'abandoned airplane',\n",
       " 'abandoned amusement',\n",
       " 'abandoned antique',\n",
       " 'abandoned art',\n",
       " 'abandoned artist',\n",
       " 'abandoned baby',\n",
       " 'abandoned birth',\n",
       " 'abandoned blackwell',\n",
       " 'abandoned bleak',\n",
       " 'abandoned boy',\n",
       " 'abandoned break',\n",
       " 'abandoned building',\n",
       " 'abandoned cabin',\n",
       " 'abandoned car',\n",
       " 'abandoned chapel',\n",
       " 'abandoned character',\n",
       " 'abandoned chess',\n",
       " 'abandoned church',\n",
       " 'abandoned city',\n",
       " 'abandoned civilized',\n",
       " 'abandoned close',\n",
       " 'abandoned coal',\n",
       " 'abandoned complex',\n",
       " 'abandoned convent',\n",
       " 'abandoned could',\n",
       " 'abandoned country',\n",
       " 'abandoned course',\n",
       " 'abandoned create',\n",
       " 'abandoned creed',\n",
       " 'abandoned cute',\n",
       " 'abandoned daughter',\n",
       " 'abandoned decent',\n",
       " 'abandoned desert',\n",
       " 'abandoned doctor',\n",
       " 'abandoned drama',\n",
       " 'abandoned driver',\n",
       " 'abandoned effort',\n",
       " 'abandoned egyptian',\n",
       " 'abandoned eight',\n",
       " 'abandoned especially',\n",
       " 'abandoned essential',\n",
       " 'abandoned everyone',\n",
       " 'abandoned exploited',\n",
       " 'abandoned fact',\n",
       " 'abandoned factory',\n",
       " 'abandoned family',\n",
       " 'abandoned father',\n",
       " 'abandoned favorite',\n",
       " 'abandoned film',\n",
       " 'abandoned filthy',\n",
       " 'abandoned first',\n",
       " 'abandoned fishing',\n",
       " 'abandoned funeral',\n",
       " 'abandoned future',\n",
       " 'abandoned garage',\n",
       " 'abandoned genius',\n",
       " 'abandoned german',\n",
       " 'abandoned ghost',\n",
       " 'abandoned gold',\n",
       " 'abandoned good',\n",
       " 'abandoned graveyard',\n",
       " 'abandoned high',\n",
       " 'abandoned hotel',\n",
       " 'abandoned house',\n",
       " 'abandoned husband',\n",
       " 'abandoned infant',\n",
       " 'abandoned institution',\n",
       " 'abandoned island',\n",
       " 'abandoned jungle',\n",
       " 'abandoned junk',\n",
       " 'abandoned kill',\n",
       " 'abandoned king',\n",
       " 'abandoned later',\n",
       " 'abandoned leaf',\n",
       " 'abandoned leaving',\n",
       " 'abandoned life',\n",
       " 'abandoned london',\n",
       " 'abandoned long',\n",
       " 'abandoned lost',\n",
       " 'abandoned lot',\n",
       " 'abandoned lover',\n",
       " 'abandoned lusty',\n",
       " 'abandoned luther',\n",
       " 'abandoned mail',\n",
       " 'abandoned man',\n",
       " 'abandoned mansion',\n",
       " 'abandoned mere',\n",
       " 'abandoned michigan',\n",
       " 'abandoned mine',\n",
       " 'abandoned monastery',\n",
       " 'abandoned moral',\n",
       " 'abandoned mother',\n",
       " 'abandoned mountain',\n",
       " 'abandoned movie',\n",
       " 'abandoned napier',\n",
       " 'abandoned naturally',\n",
       " 'abandoned never',\n",
       " 'abandoned next',\n",
       " 'abandoned not',\n",
       " 'abandoned old',\n",
       " 'abandoned one',\n",
       " 'abandoned order',\n",
       " 'abandoned orphan',\n",
       " 'abandoned parent',\n",
       " 'abandoned part',\n",
       " 'abandoned pay',\n",
       " 'abandoned penitentiary',\n",
       " 'abandoned picture',\n",
       " 'abandoned place',\n",
       " 'abandoned play',\n",
       " 'abandoned plotlines',\n",
       " 'abandoned plush',\n",
       " 'abandoned poor',\n",
       " 'abandoned pretending',\n",
       " 'abandoned prison',\n",
       " 'abandoned project',\n",
       " 'abandoned protagonist',\n",
       " 'abandoned quickly',\n",
       " 'abandoned real',\n",
       " 'abandoned refugee',\n",
       " 'abandoned remake',\n",
       " 'abandoned resolved',\n",
       " 'abandoned rich',\n",
       " 'abandoned rotting',\n",
       " 'abandoned run',\n",
       " 'abandoned russian',\n",
       " 'abandoned scene',\n",
       " 'abandoned school',\n",
       " 'abandoned see',\n",
       " 'abandoned seems',\n",
       " 'abandoned shack',\n",
       " 'abandoned shi',\n",
       " 'abandoned ship',\n",
       " 'abandoned short',\n",
       " 'abandoned shot',\n",
       " 'abandoned since',\n",
       " 'abandoned site',\n",
       " 'abandoned small',\n",
       " 'abandoned spaceship',\n",
       " 'abandoned spaniel',\n",
       " 'abandoned spark',\n",
       " 'abandoned spooky',\n",
       " 'abandoned station',\n",
       " 'abandoned stock',\n",
       " 'abandoned suddenly',\n",
       " 'abandoned summer',\n",
       " 'abandoned swimming',\n",
       " 'abandoned tacking',\n",
       " 'abandoned tell',\n",
       " 'abandoned theater',\n",
       " 'abandoned three',\n",
       " 'abandoned time',\n",
       " 'abandoned tired',\n",
       " 'abandoned toxic',\n",
       " 'abandoned train',\n",
       " 'abandoned troubled',\n",
       " 'abandoned truck',\n",
       " 'abandoned two',\n",
       " 'abandoned underground',\n",
       " 'abandoned unfinished',\n",
       " 'abandoned vacation',\n",
       " 'abandoned video',\n",
       " 'abandoned village',\n",
       " 'abandoned voice',\n",
       " 'abandoned wanted',\n",
       " 'abandoned war',\n",
       " 'abandoned warehouse',\n",
       " 'abandoned wedding',\n",
       " 'abandoned wife',\n",
       " 'abandoned wise',\n",
       " 'abandoned within',\n",
       " 'abandoned without',\n",
       " 'abandoned wood',\n",
       " 'abandoned would',\n",
       " 'abandoned year',\n",
       " 'abandoned yokai',\n",
       " 'abandoning',\n",
       " 'abandoning artistic',\n",
       " 'abandoning child',\n",
       " 'abandoning day',\n",
       " 'abandoning destroys',\n",
       " 'abandoning direction',\n",
       " 'abandoning essentially',\n",
       " 'abandoning film',\n",
       " 'abandoning historical',\n",
       " 'abandoning humanity',\n",
       " 'abandoning job',\n",
       " 'abandoning men',\n",
       " 'abandoning mosaic',\n",
       " 'abandoning one',\n",
       " 'abandoning parental',\n",
       " 'abandoning project',\n",
       " 'abandoning rule',\n",
       " 'abandoning sick',\n",
       " 'abandoning small',\n",
       " 'abandoning tito',\n",
       " 'abandoning trip',\n",
       " 'abandoning viewer',\n",
       " 'abandonment',\n",
       " 'abandonment adult',\n",
       " 'abandonment believe',\n",
       " 'abandonment child',\n",
       " 'abandonment common',\n",
       " 'abandonment course',\n",
       " 'abandonment courtenay',\n",
       " 'abandonment difficult',\n",
       " 'abandonment ego',\n",
       " 'abandonment family',\n",
       " 'abandonment great',\n",
       " 'abandonment money',\n",
       " 'abandonment mother',\n",
       " 'abandonment need',\n",
       " 'abandonment not',\n",
       " 'abandonment return',\n",
       " 'abandonment sewer',\n",
       " 'abandonment sexual',\n",
       " 'abandonment society',\n",
       " 'abandonment term',\n",
       " 'abandonment think',\n",
       " 'abandonment throw',\n",
       " 'abandonment tried',\n",
       " 'abandonment twice',\n",
       " 'abandonment yet',\n",
       " 'abashed',\n",
       " 'abashed brought',\n",
       " 'abashidze',\n",
       " 'abashidze star',\n",
       " 'abatement',\n",
       " 'abatement agony',\n",
       " 'abating',\n",
       " 'abating quite',\n",
       " 'abattoir',\n",
       " 'abattoir plus',\n",
       " 'abba',\n",
       " 'abba become',\n",
       " 'abba captain',\n",
       " 'abba constantly',\n",
       " 'abba costume',\n",
       " 'abba daughter',\n",
       " 'abba delightful',\n",
       " 'abba fall',\n",
       " 'abba fame',\n",
       " 'abba horrible',\n",
       " 'abba kind',\n",
       " 'abba name',\n",
       " 'abba not',\n",
       " 'abba song',\n",
       " 'abba soundtrack',\n",
       " 'abba vikea',\n",
       " 'abbad',\n",
       " 'abbad khan',\n",
       " 'abbas',\n",
       " 'abbas ali',\n",
       " 'abbas khan',\n",
       " 'abbas kiarostami',\n",
       " 'abbas mastan',\n",
       " 'abbas mustan',\n",
       " 'abbas responsible',\n",
       " 'abbasi',\n",
       " 'abbasi edgar',\n",
       " 'abbe',\n",
       " 'abbe lane',\n",
       " 'abbey',\n",
       " 'abbey actually',\n",
       " 'abbey bad',\n",
       " 'abbey basically',\n",
       " 'abbey castle',\n",
       " 'abbey caught',\n",
       " 'abbey could',\n",
       " 'abbey destroyed',\n",
       " 'abbey fact',\n",
       " 'abbey film',\n",
       " 'abbey find',\n",
       " 'abbey flavia',\n",
       " 'abbey give',\n",
       " 'abbey go',\n",
       " 'abbey hateful',\n",
       " 'abbey julia',\n",
       " 'abbey kells',\n",
       " 'abbey let',\n",
       " 'abbey live',\n",
       " 'abbey looked',\n",
       " 'abbey mansfield',\n",
       " 'abbey much',\n",
       " 'abbey mum',\n",
       " 'abbey never',\n",
       " 'abbey odd',\n",
       " 'abbey one',\n",
       " 'abbey parody',\n",
       " 'abbey protect',\n",
       " 'abbey released',\n",
       " 'abbey ruin',\n",
       " 'abbey satirized',\n",
       " 'abbey scene',\n",
       " 'abbey school',\n",
       " 'abbey seat',\n",
       " 'abbey seen',\n",
       " 'abbey shocked',\n",
       " 'abbey sit',\n",
       " 'abbey sort',\n",
       " 'abbey squire',\n",
       " 'abbey start',\n",
       " 'abbey success',\n",
       " 'abbey surely',\n",
       " 'abbey theatre',\n",
       " 'abbey thrown',\n",
       " 'abbey warning',\n",
       " 'abbie',\n",
       " 'abbie cornish',\n",
       " 'abbie hoffman',\n",
       " 'abbot',\n",
       " 'abbot apprentice',\n",
       " 'abbot awful',\n",
       " 'abbot build',\n",
       " 'abbot cameron',\n",
       " 'abbot cellach',\n",
       " 'abbot costello',\n",
       " 'abbot enough',\n",
       " 'abbot especially',\n",
       " 'abbot final',\n",
       " 'abbot graf',\n",
       " 'abbot hugo',\n",
       " 'abbot impersonated',\n",
       " 'abbot kell',\n",
       " 'abbot kells',\n",
       " 'abbot loving',\n",
       " 'abbot name',\n",
       " 'abbot township',\n",
       " 'abbot white',\n",
       " 'abbott',\n",
       " 'abbott always',\n",
       " 'abbott buddy',\n",
       " 'abbott carrey',\n",
       " 'abbott costell',\n",
       " 'abbott costello',\n",
       " 'abbott dinklepuss',\n",
       " 'abbott feeding',\n",
       " 'abbott get',\n",
       " 'abbott jack',\n",
       " 'abbott kathryn',\n",
       " 'abbott lou',\n",
       " 'abbott mistake',\n",
       " 'abbott not',\n",
       " 'abbott plot',\n",
       " 'abbott reliving',\n",
       " 'abbott though',\n",
       " 'abbott true',\n",
       " 'abbott usual',\n",
       " 'abbott white',\n",
       " 'abbotts',\n",
       " 'abbreviate',\n",
       " 'abbreviate title',\n",
       " 'abbreviated',\n",
       " 'abbreviated appears',\n",
       " 'abbreviated battle',\n",
       " 'abbreviated credit',\n",
       " 'abbreviated dsds',\n",
       " 'abbreviated episode',\n",
       " 'abbreviated film',\n",
       " 'abbreviated form',\n",
       " 'abbreviated length',\n",
       " 'abbreviated ramo',\n",
       " 'abbreviated wrong',\n",
       " 'abbreviating',\n",
       " 'abbreviating actual',\n",
       " 'abbu',\n",
       " 'abbu aba',\n",
       " 'abbu abbas',\n",
       " 'abby',\n",
       " 'abby blackmail',\n",
       " 'abby die',\n",
       " 'abby disappearing',\n",
       " 'abby engaged',\n",
       " 'abby final',\n",
       " 'abby find',\n",
       " 'abby fully',\n",
       " 'abby get',\n",
       " 'abby go',\n",
       " 'abby group',\n",
       " 'abby however',\n",
       " 'abby julia',\n",
       " 'abby life',\n",
       " 'abby looked',\n",
       " 'abby mum',\n",
       " 'abby not',\n",
       " 'abby plan',\n",
       " 'abby played',\n",
       " 'abby russell',\n",
       " 'abby say',\n",
       " 'abby sex',\n",
       " 'abby show',\n",
       " 'abby skin',\n",
       " 'abby something',\n",
       " 'abby took',\n",
       " 'abby true',\n",
       " 'abby uniform',\n",
       " 'abby worst',\n",
       " 'abbyss',\n",
       " 'abbyss anyway',\n",
       " 'abc',\n",
       " 'abc abc',\n",
       " 'abc actually',\n",
       " 'abc affiliate',\n",
       " 'abc afterschool',\n",
       " 'abc australian',\n",
       " 'abc award',\n",
       " 'abc back',\n",
       " 'abc basically',\n",
       " 'abc best',\n",
       " 'abc brings',\n",
       " 'abc brought',\n",
       " 'abc canceled',\n",
       " 'abc cancellation',\n",
       " 'abc cbs',\n",
       " 'abc celebration',\n",
       " 'abc chocking',\n",
       " 'abc classic',\n",
       " 'abc com',\n",
       " 'abc could',\n",
       " 'abc create',\n",
       " 'abc decided',\n",
       " 'abc disney',\n",
       " 'abc done',\n",
       " 'abc dropped',\n",
       " 'abc dvd',\n",
       " 'abc email',\n",
       " 'abc even',\n",
       " 'abc executive',\n",
       " 'abc faddish',\n",
       " 'abc family',\n",
       " 'abc far',\n",
       " 'abc fault',\n",
       " 'abc fighting',\n",
       " 'abc finally',\n",
       " 'abc forever',\n",
       " 'abc forgot',\n",
       " 'abc friday',\n",
       " 'abc get',\n",
       " 'abc given',\n",
       " 'abc giving',\n",
       " 'abc good',\n",
       " 'abc got',\n",
       " 'abc hennessy',\n",
       " 'abc http',\n",
       " 'abc huge',\n",
       " 'abc impressive',\n",
       " 'abc improv',\n",
       " 'abc inexplicably',\n",
       " 'abc know',\n",
       " 'abc lack',\n",
       " 'abc last',\n",
       " 'abc licensed',\n",
       " 'abc long',\n",
       " 'abc lost',\n",
       " 'abc loved',\n",
       " 'abc made',\n",
       " 'abc magic',\n",
       " 'abc make',\n",
       " 'abc message',\n",
       " 'abc movie',\n",
       " 'abc much',\n",
       " 'abc murder',\n",
       " 'abc mystery',\n",
       " 'abc near',\n",
       " 'abc net',\n",
       " 'abc network',\n",
       " 'abc never',\n",
       " 'abc new',\n",
       " 'abc not',\n",
       " 'abc one',\n",
       " 'abc owned',\n",
       " 'abc picked',\n",
       " 'abc playing',\n",
       " 'abc pretty',\n",
       " 'abc program',\n",
       " 'abc proud',\n",
       " 'abc quoted',\n",
       " 'abc reality',\n",
       " 'abc regularly',\n",
       " 'abc release',\n",
       " 'abc repeated',\n",
       " 'abc replace',\n",
       " 'abc reported',\n",
       " 'abc restaurant',\n",
       " 'abc satred',\n",
       " 'abc school',\n",
       " 'abc sears',\n",
       " 'abc seeing',\n",
       " 'abc series',\n",
       " 'abc show',\n",
       " 'abc showing',\n",
       " 'abc small',\n",
       " 'abc straight',\n",
       " 'abc sunday',\n",
       " 'abc tacit',\n",
       " 'abc taken',\n",
       " 'abc tgif',\n",
       " 'abc thought',\n",
       " 'abc trying',\n",
       " 'abc two',\n",
       " 'abc usa',\n",
       " 'abc version',\n",
       " 'abc video',\n",
       " 'abc website',\n",
       " 'abc week',\n",
       " 'abc worst',\n",
       " 'abc would',\n",
       " 'abc year',\n",
       " 'abc zucker',\n",
       " 'abcd',\n",
       " 'abcd bachelor',\n",
       " 'abd',\n",
       " 'abd delightful',\n",
       " 'abd present',\n",
       " 'abdalla',\n",
       " 'abdalla older',\n",
       " 'abdic',\n",
       " 'abdic bosnian',\n",
       " 'abdic prevented',\n",
       " 'abdicates',\n",
       " 'abdicates awful',\n",
       " 'abdomen',\n",
       " 'abdomen finish',\n",
       " 'abdomen pull',\n",
       " 'abdomen sure',\n",
       " 'abdominal',\n",
       " 'abdominal agony',\n",
       " 'abdominal tumor',\n",
       " 'abdoo',\n",
       " 'abdoo hysterical',\n",
       " 'abduct',\n",
       " 'abduct believing',\n",
       " 'abduct first',\n",
       " 'abduct henchman',\n",
       " 'abduct lad',\n",
       " 'abduct lovely',\n",
       " 'abduct people',\n",
       " 'abduct ugly',\n",
       " 'abducted',\n",
       " 'abducted alien',\n",
       " 'abducted alley',\n",
       " 'abducted arab',\n",
       " 'abducted asian',\n",
       " 'abducted dealer',\n",
       " 'abducted dozen',\n",
       " 'abducted ensure',\n",
       " 'abducted evil',\n",
       " 'abducted first',\n",
       " 'abducted fleeting',\n",
       " 'abducted forced',\n",
       " 'abducted gang',\n",
       " 'abducted group',\n",
       " 'abducted home',\n",
       " 'abducted hostage',\n",
       " 'abducted indian',\n",
       " 'abducted jeff',\n",
       " 'abducted killer',\n",
       " 'abducted leave',\n",
       " 'abducted little',\n",
       " 'abducted man',\n",
       " 'abducted menacing',\n",
       " 'abducted mexican',\n",
       " 'abducted mother',\n",
       " 'abducted nearly',\n",
       " 'abducted not',\n",
       " 'abducted one',\n",
       " 'abducted photographer',\n",
       " 'abducted preserved',\n",
       " 'abducted public',\n",
       " 'abducted quartet',\n",
       " 'abducted raped',\n",
       " 'abducted seduced',\n",
       " 'abducted serve',\n",
       " 'abducted service',\n",
       " 'abducted sexually',\n",
       " 'abducted slavery',\n",
       " 'abducted someone',\n",
       " 'abducted strange',\n",
       " 'abducted suddenly',\n",
       " 'abducted wife',\n",
       " 'abducted woman',\n",
       " 'abducting',\n",
       " 'abducting burying',\n",
       " ...]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting all list of features or words \n",
    "count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['absurd quite', 'absurd rather', 'absurd rating',\n",
       "       'absurd reaction', 'absurd reference', 'absurd regard',\n",
       "       'absurd renny', 'absurd result', 'absurd revelation',\n",
       "       'absurd ride', 'absurd ridiculous', 'absurd road',\n",
       "       'absurd romance', 'absurd rule', 'absurd said', 'absurd sake',\n",
       "       'absurd scenario', 'absurd scheider', 'absurd seemed',\n",
       "       'absurd self', 'absurd serious', 'absurd setting', 'absurd sight',\n",
       "       'absurd silliness', 'absurd sinister', 'absurd situation',\n",
       "       'absurd sivaji', 'absurd sometimes', 'absurd sound',\n",
       "       'absurd soundtrack', 'absurd space', 'absurd stagebound',\n",
       "       'absurd stealing', 'absurd story', 'absurd stupid', 'absurd style',\n",
       "       'absurd sucker', 'absurd suddenly', 'absurd superman',\n",
       "       'absurd surreal', 'absurd take', 'absurd ted', 'absurd tedious',\n",
       "       'absurd terrible', 'absurd theory', 'absurd thing', 'absurd think',\n",
       "       'absurd though', 'absurd thre', 'absurd tired', 'absurd trash',\n",
       "       'absurd turn', 'absurd turning', 'absurd twist', 'absurd two',\n",
       "       'absurd unbearable', 'absurd unbelievable', 'absurd usually',\n",
       "       'absurd valid', 'absurd view', 'absurd violence', 'absurd wait',\n",
       "       'absurd wasting', 'absurd way', 'absurd welcome', 'absurd well',\n",
       "       'absurd western', 'absurd without', 'absurd word', 'absurd work',\n",
       "       'absurd workload', 'absurd worse', 'absurd woven', 'absurd writer',\n",
       "       'absurd yes', 'absurd yet', 'absurd zoey', 'absurd zombie',\n",
       "       'absurd zone', 'absurdest', 'absurdest twisted', 'absurdism',\n",
       "       'absurdism animation', 'absurdism constitute',\n",
       "       'absurdism minimalism', 'absurdism positive', 'absurdist',\n",
       "       'absurdist comedy', 'absurdist commentary', 'absurdist dark',\n",
       "       'absurdist documentary', 'absurdist endurance', 'absurdist ethos',\n",
       "       'absurdist imagery', 'absurdist masterpiece', 'absurdist period',\n",
       "       'absurdist play', 'absurdist playwright', 'absurdist premise',\n",
       "       'absurdist puppet', 'absurdist sculpture', 'absurdist self',\n",
       "       'absurdist tendency', 'absurdist ultra', 'absurdist way',\n",
       "       'absurdist word', 'absurdit', 'absurdit would', 'absurdity',\n",
       "       'absurdity absurdism', 'absurdity absurdity', 'absurdity actor',\n",
       "       'absurdity adult', 'absurdity american', 'absurdity anyone',\n",
       "       'absurdity background', 'absurdity begin', 'absurdity behind',\n",
       "       'absurdity biggest', 'absurdity biting', 'absurdity bomb',\n",
       "       'absurdity bond', 'absurdity bureaucracy', 'absurdity character',\n",
       "       'absurdity cherry', 'absurdity chuckle', 'absurdity constitutes',\n",
       "       'absurdity cruelty', 'absurdity culture', 'absurdity day',\n",
       "       'absurdity despair', 'absurdity doggie', 'absurdity done',\n",
       "       'absurdity dry', 'absurdity elite', 'absurdity even',\n",
       "       'absurdity far', 'absurdity fast', 'absurdity favor',\n",
       "       'absurdity film', 'absurdity full', 'absurdity genuinely',\n",
       "       'absurdity going', 'absurdity hat', 'absurdity hole',\n",
       "       'absurdity inanity', 'absurdity instead', 'absurdity lastly',\n",
       "       'absurdity law', 'absurdity life', 'absurdity like',\n",
       "       'absurdity line', 'absurdity living', 'absurdity logic',\n",
       "       'absurdity make', 'absurdity men', 'absurdity mind',\n",
       "       'absurdity movie', 'absurdity nice', 'absurdity none',\n",
       "       'absurdity not', 'absurdity obscenity', 'absurdity performance',\n",
       "       'absurdity plot', 'absurdity point', 'absurdity pop',\n",
       "       'absurdity premise', 'absurdity pure', 'absurdity rather',\n",
       "       'absurdity realistic', 'absurdity really', 'absurdity revolving',\n",
       "       'absurdity rise', 'absurdity samantha', 'absurdity satire',\n",
       "       'absurdity see', 'absurdity shaw', 'absurdity simply',\n",
       "       'absurdity situation', 'absurdity something', 'absurdity sparkle',\n",
       "       'absurdity star', 'absurdity strictly', 'absurdity supposed',\n",
       "       'absurdity take', 'absurdity thing', 'absurdity three',\n",
       "       'absurdity time', 'absurdity together', 'absurdity truth',\n",
       "       'absurdity undermines', 'absurdity unlike', 'absurdity various',\n",
       "       'absurdity waiting', 'absurdity war', 'absurdity watched',\n",
       "       'absurdity within', 'absurdity work', 'absurdity woven',\n",
       "       'absurdity yet', 'absurdity zoolander', 'absurdly', 'absurdly bad',\n",
       "       'absurdly badly', 'absurdly complicated', 'absurdly convoluted',\n",
       "       'absurdly designed', 'absurdly entertaining', 'absurdly fake',\n",
       "       'absurdly frilly', 'absurdly grotesque', 'absurdly happy',\n",
       "       'absurdly high', 'absurdly hilarious', 'absurdly hot',\n",
       "       'absurdly idiosyncratic', 'absurdly interesting', 'absurdly long',\n",
       "       'absurdly loutish', 'absurdly low', 'absurdly outlandish',\n",
       "       'absurdly praised', 'absurdly ridiculous', 'absurdly simplistic',\n",
       "       'absurdly still', 'absurdly stupid', 'absurdly unbelievable',\n",
       "       'absurdly unreal', 'absurdly unrealistic', 'absurdly vanessa',\n",
       "       'absurdly wrong', 'absurdness', 'absurdness easily',\n",
       "       'absurdness serbian', 'abt', 'abt actually', 'abu', 'abu become',\n",
       "       'abu becomes', 'abu conrad', 'abu fight', 'abu garib', 'abu genie',\n",
       "       'abu ghraib', 'abu graib', 'abu hamza', 'abu john', 'abu played',\n",
       "       'abu put', 'abu suffer', 'abu sympathetic', 'abu thief',\n",
       "       'abu triumphantly', 'abudantly', 'abudantly clear', 'abuelita',\n",
       "       'abuelita altagracia', 'abuhab', 'abuhab periodically',\n",
       "       'abundance', 'abundance around', 'abundance astutely',\n",
       "       'abundance bad', 'abundance beautiful', 'abundance better',\n",
       "       'abundance blankfield', 'abundance bottom', 'abundance cameo',\n",
       "       'abundance camp', 'abundance carol', 'abundance cgi',\n",
       "       'abundance characterization', 'abundance charm', 'abundance cheap',\n",
       "       'abundance clich', 'abundance comic', 'abundance common',\n",
       "       'abundance concept', 'abundance corrupted', 'abundance death',\n",
       "       'abundance disease', 'abundance due', 'abundance ending',\n",
       "       'abundance enrich', 'abundance fact', 'abundance female',\n",
       "       'abundance film', 'abundance flaw', 'abundance flesh',\n",
       "       'abundance foul', 'abundance girl', 'abundance good',\n",
       "       'abundance gratuitous', 'abundance hair', 'abundance higher',\n",
       "       'abundance home', 'abundance incident', 'abundance killer',\n",
       "       'abundance martial', 'abundance material', 'abundance memorable',\n",
       "       'abundance monica', 'abundance movie', 'abundance naked',\n",
       "       'abundance narcissism', 'abundance next', 'abundance nudity',\n",
       "       'abundance one', 'abundance poor', 'abundance quality',\n",
       "       'abundance rocking', 'abundance ryan', 'abundance sex',\n",
       "       'abundance shock', 'abundance sleazy', 'abundance talk',\n",
       "       'abundance terrain', 'abundance thrill', 'abundance violence',\n",
       "       'abundance zombie', 'abundant', 'abundant believe',\n",
       "       'abundant classic', 'abundant day', 'abundant emotionally',\n",
       "       'abundant fact', 'abundant female', 'abundant flaw',\n",
       "       'abundant flipper', 'abundant happens', 'abundant house',\n",
       "       'abundant including', 'abundant nemesis', 'abundant nudity',\n",
       "       'abundant profane', 'abundant promise', 'abundant puzzle',\n",
       "       'abundant quantity', 'abundant racial', 'abundant rather',\n",
       "       'abundant raw', 'abundant recent', 'abundant reproduction',\n",
       "       'abundant resource', 'abundant symbolism', 'abundant usually',\n",
       "       'abundantly', 'abundantly clear', 'abundantly clearer',\n",
       "       'abundantly gifted', 'abundantly obvious', 'abundantly personally',\n",
       "       'abundantly rewarded', 'abundantly talented', 'abuse',\n",
       "       'abuse abandonment', 'abuse abuse', 'abuse according',\n",
       "       'abuse adoption', 'abuse adult', 'abuse affair', 'abuse affect',\n",
       "       'abuse alcohol', 'abuse although', 'abuse amanda', 'abuse another',\n",
       "       'abuse apparently', 'abuse attractive', 'abuse authority',\n",
       "       'abuse bad', 'abuse battered', 'abuse becomes', 'abuse begin',\n",
       "       'abuse birthday', 'abuse bloodshed', 'abuse bobby', 'abuse bore',\n",
       "       'abuse bos', 'abuse cameroon', 'abuse challenger', 'abuse child',\n",
       "       'abuse chronic', 'abuse church', 'abuse committed',\n",
       "       'abuse complaint', 'abuse completely', 'abuse constant',\n",
       "       'abuse coolest', 'abuse crap', 'abuse credit', 'abuse cropping',\n",
       "       'abuse cruelty', 'abuse cynical', 'abuse daughter', 'abuse dealt',\n",
       "       'abuse defames', 'abuse degradation', 'abuse deserted',\n",
       "       'abuse destroys', 'abuse deviousness', 'abuse disabled',\n",
       "       'abuse displaced', 'abuse domestic', 'abuse done', 'abuse drawn',\n",
       "       'abuse drug', 'abuse duress', 'abuse emasculating',\n",
       "       'abuse emotional', 'abuse end', 'abuse endured',\n",
       "       'abuse environment', 'abuse essentially', 'abuse etc',\n",
       "       'abuse even', 'abuse eventually', 'abuse ever', 'abuse excuse',\n",
       "       'abuse exist', 'abuse exploitation', 'abuse family',\n",
       "       'abuse fantastic', 'abuse father', 'abuse fecal', 'abuse film',\n",
       "       'abuse folk', 'abuse forced', 'abuse found', 'abuse frame',\n",
       "       'abuse frat', 'abuse fresh', 'abuse friend', 'abuse gave',\n",
       "       'abuse going', 'abuse good', 'abuse grandmother', 'abuse graphic',\n",
       "       'abuse guess', 'abuse guilt', 'abuse hand', 'abuse handicapped',\n",
       "       'abuse heaped', 'abuse heather', 'abuse hedonism', 'abuse hinted',\n",
       "       'abuse hitchcock', 'abuse hold', 'abuse horse', 'abuse humiliate',\n",
       "       'abuse humour', 'abuse hypocrisy', 'abuse implied',\n",
       "       'abuse includes', 'abuse increasingly', 'abuse inflicted',\n",
       "       'abuse innocent', 'abuse inspiration', 'abuse jackson',\n",
       "       'abuse jew', 'abuse joke', 'abuse keep', 'abuse keeping',\n",
       "       'abuse kid', 'abuse kidnapping', 'abuse killing', 'abuse knowing',\n",
       "       'abuse lawless', 'abuse leading', 'abuse let', 'abuse loneliness',\n",
       "       'abuse look', 'abuse looping', 'abuse lord', 'abuse make',\n",
       "       'abuse male', 'abuse manner', 'abuse may', 'abuse maybe',\n",
       "       'abuse mazzello', 'abuse mean', 'abuse mechanism', 'abuse medium',\n",
       "       'abuse men', 'abuse midst', 'abuse might', 'abuse miss',\n",
       "       'abuse movie', 'abuse must', 'abuse mutilated', 'abuse nature',\n",
       "       'abuse neglect', 'abuse never', 'abuse new', 'abuse not',\n",
       "       'abuse older', 'abuse one', 'abuse opposed', 'abuse overly',\n",
       "       'abuse paragraph', 'abuse parent', 'abuse perpetrator',\n",
       "       'abuse phony', 'abuse physical', 'abuse police', 'abuse position',\n",
       "       'abuse power', 'abuse presented', 'abuse privilege',\n",
       "       'abuse problem', 'abuse progress', 'abuse psychological',\n",
       "       'abuse rated', 'abuse rather', 'abuse realistic', 'abuse really',\n",
       "       'abuse received', 'abuse redemption', 'abuse refusal',\n",
       "       'abuse religion', 'abuse renouncing', 'abuse reviewer',\n",
       "       'abuse rough', 'abuse ruth', 'abuse scarred', 'abuse scene',\n",
       "       'abuse school', 'abuse second', 'abuse seemingly', 'abuse selfish',\n",
       "       'abuse send', 'abuse sense', 'abuse severe', 'abuse sex',\n",
       "       'abuse sexual', 'abuse shock', 'abuse shylock', 'abuse side',\n",
       "       'abuse simply', 'abuse single', 'abuse slow', 'abuse somehow',\n",
       "       'abuse someone', 'abuse soon', 'abuse sound', 'abuse speak',\n",
       "       'abuse start', 'abuse steely', 'abuse student', 'abuse stupid',\n",
       "       'abuse suffered', 'abuse suffers', 'abuse sufficient',\n",
       "       'abuse superior', 'abuse survive', 'abuse swope', 'abuse syrupy',\n",
       "       'abuse take', 'abuse talent', 'abuse technical', 'abuse teen',\n",
       "       'abuse tell', 'abuse thank', 'abuse think', 'abuse though',\n",
       "       'abuse tiananmen', 'abuse time', 'abuse topic', 'abuse torment',\n",
       "       'abuse torture', 'abuse towards', 'abuse treat', 'abuse try',\n",
       "       'abuse two', 'abuse ugly', 'abuse ultimately', 'abuse unconscious',\n",
       "       'abuse underling', 'abuse unnecesary', 'abuse verbally',\n",
       "       'abuse violence', 'abuse well', 'abuse west', 'abuse wife',\n",
       "       'abuse wii', 'abuse without', 'abuse woman', 'abuse word',\n",
       "       'abuse would', 'abuse wrong', 'abuse year', 'abuse yet',\n",
       "       'abuse young', 'abused', 'abused abandoned', 'abused abusive',\n",
       "       'abused adopted', 'abused adult', 'abused antwone',\n",
       "       'abused anyone', 'abused awakened', 'abused battered',\n",
       "       'abused begin', 'abused beginning', 'abused bellboy',\n",
       "       'abused best', 'abused boy', 'abused cat', 'abused child',\n",
       "       'abused childhood', 'abused chinese', 'abused completely',\n",
       "       'abused could', 'abused coveted', 'abused damaged',\n",
       "       'abused daughter', 'abused day', 'abused deaf', 'abused dildo',\n",
       "       'abused dog', 'abused drugged', 'abused drunk', 'abused drunken',\n",
       "       'abused employee', 'abused every', 'abused farm', 'abused father',\n",
       "       'abused fierce', 'abused film', 'abused getting', 'abused girl',\n",
       "       'abused hero', 'abused housewife', 'abused hurt',\n",
       "       'abused instrument', 'abused insulted', 'abused kid',\n",
       "       'abused large', 'abused largely', 'abused left', 'abused like',\n",
       "       'abused little', 'abused make', 'abused master', 'abused men',\n",
       "       'abused model', 'abused molested', 'abused mostly',\n",
       "       'abused mother', 'abused neglected', 'abused never', 'abused next',\n",
       "       'abused nice', 'abused not', 'abused often', 'abused one',\n",
       "       'abused others', 'abused phrase', 'abused picked',\n",
       "       'abused powerless', 'abused prison'], dtype='<U145')"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_array = np.array(count_vect.get_feature_names())\n",
    "feature_array[5000:5660]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz',\n",
       "       'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz excuse',\n",
       "       'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz',\n",
       "       'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz ooops',\n",
       "       'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz', 'zzzzzzzzzzzzzzzzzz imdb',\n",
       "       'zzzzzzzzzzzzzzzzzz', 'zzzzzzzzzzzzz way', 'zzzzzzzzzzzzz',\n",
       "       'zzzzzzzzzzzz pop'], dtype='<U145')"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting top 10 words with most appearance\n",
    "responses = feature_array\n",
    "tfidf_sorting = np.argsort(responses).flatten()[::-1]\n",
    "\n",
    "n = 10\n",
    "top_n = feature_array[tfidf_sorting][:n]\n",
    "top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-Fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=10, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulate splitting a dataset of 25 observations into 5 folds\n",
    "kf = KFold(n_splits=10) #, shuffle=True, random_state=25)\n",
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration                   Training set obsevations                    Testing set observations\n",
      "    1                        [1 2 3 4 5 6 7 8 9]                                  [0]              \n",
      "    2                        [0 2 3 4 5 6 7 8 9]                                  [1]              \n",
      "    3                        [0 1 3 4 5 6 7 8 9]                                  [2]              \n",
      "    4                        [0 1 2 4 5 6 7 8 9]                                  [3]              \n",
      "    5                        [0 1 2 3 5 6 7 8 9]                                  [4]              \n",
      "    6                        [0 1 2 3 4 6 7 8 9]                                  [5]              \n",
      "    7                        [0 1 2 3 4 5 7 8 9]                                  [6]              \n",
      "    8                        [0 1 2 3 4 5 6 8 9]                                  [7]              \n",
      "    9                        [0 1 2 3 4 5 6 7 9]                                  [8]              \n",
      "   10                        [0 1 2 3 4 5 6 7 8]                                  [9]              \n"
     ]
    }
   ],
   "source": [
    "# remove\n",
    "print('{} {:^61} {}'.format('Iteration', 'Training set obsevations', 'Testing set observations'))\n",
    "for iteration,data in enumerate(kf.split(range(10)), start=1):\n",
    "#     print(data)\n",
    "#     print(iteration)\n",
    "#     print(iteration,data)\n",
    "    print('{!s:^9} {!s:^58} {!s:^30}'.format(iteration, data[0],data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# remove\n",
    "def get_score (model,X_train,y_train,X_test,y_test):\n",
    "    model.fit(X_train,y_train)\n",
    "    return model.predict(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration                   Training set obsevations                    Testing set observations\n",
      "[ 6942  6943  6944 ... 34704 34705 34706] [   0    1    2 ... 6939 6940 6941]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-fcecda1e74a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#     X_train_train, X_train_test, y_train_train, y_train_test = X_train[iteration],X_train[data],y_train[iteration],y_train[data]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#     print(get_score(CategoricalNB(), X_train_train, X_train_test, y_train_train, y_train_test))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda-Python\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    908\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda-Python\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    941\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"integer\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 943\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    944\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda-Python\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1768\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1770\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda-Python\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1952\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1954\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1956\u001b[0m             \u001b[1;31m# nested tuple slicing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda-Python\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1593\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1594\u001b[0m             \u001b[1;31m# A collection of keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1595\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1596\u001b[0m             return self.obj._reindex_with_indexers(\n\u001b[0;32m   1597\u001b[0m                 \u001b[1;33m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda-Python\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1550\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1552\u001b[1;33m         self._validate_read_indexer(\n\u001b[0m\u001b[0;32m   1553\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1554\u001b[0m         )\n",
      "\u001b[1;32mF:\\Anaconda-Python\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1652\u001b[0m             \u001b[1;31m# just raising\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1653\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_interval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1654\u001b[1;33m                 raise KeyError(\n\u001b[0m\u001b[0;32m   1655\u001b[0m                     \u001b[1;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1656\u001b[0m                     \u001b[1;34m\"is no longer supported, see \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'"
     ]
    }
   ],
   "source": [
    "# remove\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "print('{} {:^61} {}'.format('Iteration', 'Training set obsevations', 'Testing set observations'))\n",
    "for iteration,data in kf.split(X_train):\n",
    "#     print(iteration,data)\n",
    "#     print(X_train[data])\n",
    "#     X_train_train, X_train_test, y_train_train, y_train_test = X_train[iteration],X_train[data],y_train[iteration],y_train[data]\n",
    "#     print(get_score(CategoricalNB(), X_train_train, X_train_test, y_train_train, y_train_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial model with alpha = 0.0001 have mean 85.14994723675876 and standard deviation 0.8514994723675876\n",
      "Multinomial model with alpha = 0.1 have mean 87.52123440246355 and standard deviation 0.8752123440246355\n",
      "Multinomial model with alpha = 0.1 have mean 87.52123440246355 and standard deviation 0.8752123440246355\n",
      "Multinomial model with alpha = 1 have mean 87.9361195313661 and standard deviation 0.879361195313661\n",
      "Multinomial model with alpha = 10 have mean 87.49239935339084 and standard deviation 0.8749239935339084\n",
      "Multinomial model with alpha = 20 have mean 87.1149557843208 and standard deviation 0.871149557843208\n",
      "Multinomial model with alpha = 200 have mean 84.9050377894402 and standard deviation 0.8490503778944021\n",
      "Multinomial model with alpha = 2000 have mean 79.04454197272253 and standard deviation 0.7904454197272253\n",
      "Multinomial model with alpha = 20000 have mean 68.15912247797102 and standard deviation 0.6815912247797102\n",
      "Multinomial model with alpha = 2000000 have mean 65.27211468926976 and standard deviation 0.6527211468926976\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.0001,00.1,0.1,1,10,20,200,2000,20000,2000000]\n",
    "for i in alphas:\n",
    "    print('''Multinomial model with alpha = {} have mean {} and standard deviation {}''' \\\n",
    "          .format(i,(cross_val_score(MultinomialNB(alpha=i),x_train_count,y_train,cv=10).mean())*100,cross_val_score(MultinomialNB(alpha=i),x_train_count,y_train,cv=10).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB(alpha=1)\n",
    "model.fit(x_train_count,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_count,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9959086063330164"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_train_count,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-750a4b90ce76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: predict() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "model.predict(x_test_count,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 5.69418085e-23],\n",
       "       [3.23408478e-06, 9.99996766e-01],\n",
       "       [2.74476561e-07, 9.99999726e-01],\n",
       "       ...,\n",
       "       [3.76080015e-29, 1.00000000e+00],\n",
       "       [9.79189752e-01, 2.08102481e-02],\n",
       "       [1.00000000e+00, 6.68614728e-18]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_proba(x_test_count) \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test_count) \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6639  765]\n",
      " [ 984 6487]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8824201680672269"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
