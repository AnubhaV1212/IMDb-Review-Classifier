{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Dataset of 50K Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB dataset having 50K movie reviews for Text classification using Multinomial Naive Bayes.\n",
    "\n",
    "This is a dataset for binary sentiment classification.\n",
    "\n",
    "We provide a set of 25,000 highly polar movie reviews for training and 25,000 for testing.\n",
    "\n",
    "For more dataset information, please go through the following link,\n",
    "http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "Data Source: https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [0]. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split , KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix , accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
    "import re\n",
    "import string\n",
    "# Library for stopwords\n",
    "from nltk.corpus import stopwords\n",
    "# Library for Stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "# Library for Lemmatizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1]. Reading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.1] Loading the data\n",
    "\n",
    "The dataset is available in .csv File forms\n",
    "\n",
    "Here as we only want to get the global sentiment of the recommendations (positive or negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# importing the dataset\n",
    "df = pd.read_csv('IMDB dataset.csv')\n",
    "# to check the structure of dataset and is there any null value\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# priniting top 5 rows to have a look on how data look like\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive    25000\n",
      "negative    25000\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.sentiment.value_counts())      # print(dataset['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\b\b\b\bA Turkish Bath sequence in a film noir loc...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!! Spoiler alert!!!&lt;br /&gt;&lt;br /&gt;The point is, ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!! MILD SPOILERS !!!!&lt;br /&gt;&lt;br /&gt;The premise...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!! MILD SPOILERS !!!!&lt;br /&gt;&lt;br /&gt;With the ex...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!! POSSIBLE MILD SPOILER !!!!!&lt;br /&gt;&lt;br /&gt;As...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49577</th>\n",
       "      <td>{Possible spoilers coming up... you've been fo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49578</th>\n",
       "      <td>{rant start} I didn't want to believe them at ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49579</th>\n",
       "      <td>~~I was able to see this movie yesterday morni...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49580</th>\n",
       "      <td>Film auteur Stephan Woloszczuk explores th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49581</th>\n",
       "      <td>ý thýnk uzak ýs the one of the best films of a...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49582 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  count\n",
       "0      \b\b\b\bA Turkish Bath sequence in a film noir loc...  positive      1\n",
       "1      !!! Spoiler alert!!!<br /><br />The point is, ...  negative      1\n",
       "2      !!!! MILD SPOILERS !!!!<br /><br />The premise...  negative      1\n",
       "3      !!!! MILD SPOILERS !!!!<br /><br />With the ex...  negative      1\n",
       "4      !!!! POSSIBLE MILD SPOILER !!!!!<br /><br />As...  negative      1\n",
       "...                                                  ...       ...    ...\n",
       "49577  {Possible spoilers coming up... you've been fo...  positive      1\n",
       "49578  {rant start} I didn't want to believe them at ...  negative      1\n",
       "49579  ~~I was able to see this movie yesterday morni...  positive      1\n",
       "49580      Film auteur Stephan Woloszczuk explores th...  positive      1\n",
       "49581  ý thýnk uzak ýs the one of the best films of a...  positive      1\n",
       "\n",
       "[49582 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count = df.groupby(['review', 'sentiment']).size().reset_index(name='count')\n",
    "df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26260    5\n",
       "11782    4\n",
       "48038    3\n",
       "27652    3\n",
       "30884    3\n",
       "        ..\n",
       "32982    1\n",
       "32981    1\n",
       "32980    1\n",
       "32979    1\n",
       "0        1\n",
       "Name: count, Length: 49582, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count['count'].sort_values( axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "1. Dataset have 2 columns i.e. Review and Sentiment\n",
    "2. Review on whatever written by user and sentiment is whether they like the movie or not \n",
    "3. Dataset is of binary classification type, since sentiment is either positive, if user like the movie or negative, if user dislike the movie\n",
    "4. Dataset have no null value and it is balanced data\n",
    "5. Here we observe data duplication, so we need to do Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2.1] Data Cleaning: Deduplication\n",
    "It is observed (as shown in the table above) that the reviews data had duplicate entries. Hence it was necessary to remove duplicates in order to get unbiased results for the analysis of the data. Following is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review       Loved today's show!!! It was a variety and not...\n",
      "sentiment                                             positive\n",
      "count                                                        5\n",
      "Name: 26260, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_count.iloc[26260])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 49582 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     49582 non-null  object\n",
      " 1   sentiment  49582 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#Deduplication of entries\n",
    "df.drop_duplicates(subset={'review','sentiment'}, keep='first', inplace=True, ignore_index=False)\n",
    "\n",
    "# after deduplication again check the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resolving another problem of replacing cateogry feature with ordinal numeric value\n",
    "1 for Positive\n",
    "0 for Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  response\n",
       "0  One of the other reviewers has mentioned that ...  positive         1\n",
       "1  A wonderful little production. <br /><br />The...  positive         1\n",
       "2  I thought this was a wonderful way to spend ti...  positive         1\n",
       "3  Basically there's a family where a little boy ...  negative         0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive         1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating another column, with column name as response positive ---> 1 and negative ---> 0 \n",
    "df['response'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# firstly dropping sentiment column and then rename response column to sentiment\n",
    "del df['sentiment']\n",
    "df=df.rename(columns = {'response':'sentiment'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8360000000000034"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((1-((df['sentiment'].size*1.0)/(50000*1.0)))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lost due to DeDuplcatin 0.008360000000000034 %\n"
     ]
    }
   ],
   "source": [
    "#Checking to see how much % of data still remains\n",
    "print('Total lost due to DeDuplcatin {} %'.format(((1-((df['sentiment'].size*1.0)/(50000*1.0))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical value converted to Numerical value\n",
    "1. Sentiment column value changed from categorical to numerical\n",
    "2. Positive value converted to 1 and negative value converted to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Text pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data before doing data pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of row of training dataset review: 34707\n",
      "no of row of training dataset sentiment: 34707\n"
     ]
    }
   ],
   "source": [
    "print('no of row of training dataset review:',len(x_train))\n",
    "print('no of row of training dataset sentiment:',len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of row of test dataset review: 14875\n",
      "no of row of test dataset sentiment: 14875\n"
     ]
    }
   ],
   "source": [
    "print('no of row of test dataset review:',len(x_test))\n",
    "print('no of row of test dataset sentiment:',len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have finished deduplication our data requires some preprocessing before we go on further with analysis and making the prediction model.\n",
    "\n",
    "Hence in the Preprocessing phase we do the following in the order below:-\n",
    "\n",
    "1. Begin by removing the html tags\n",
    "2. Remove any punctuations or limited set of special characters like , or . or # etc.\n",
    "3. Check if the word is made up of english letters and is not alpha-numeric\n",
    "4. Check to see if the length of the word is greater than 2 (as it was researched that there is no adjective in 2-letters)\n",
    "5. Convert the word to lowercase\n",
    "6. Remove Stopwords<br>\n",
    "8. Finally use Lemmantizer\n",
    "\n",
    "Create function for all user work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clear all html tags\n",
    "def clearHtml(sentence):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleanText = re.sub(cleanr,' ',sentence)\n",
    "    return cleanText       # output is in string\n",
    "# Function to clear all extra symbols except single quote\n",
    "def clearPunc(sentence):\n",
    "#     cleaned = re.sub(r'[?|!\\|\"|#|.|,|)|(\\||\\\\|/|:]',r' ',sentence)\n",
    "    cleaned = re.sub('[^A-Za-z0-9\\']+', ' ', sentence)\n",
    "    return cleaned        # output is in string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert common contractions to Normal words\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove all other single quotes after treating common contraction\n",
    "def clearRestSingleQuotes(sentence):\n",
    "    cleaned = re.sub('[^A-Za-z0-9]+', ' ', sentence)\n",
    "    return cleaned  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a', \"should've\", 'ours', 'i', \"that'll\", 'are', 'herself', 'what', 'had', 'into', \"you're\", 'wasn', 'any', 'because', 'aren', 'while', 'be', 'out', 'each', 'll', 'ain', 'd', 'this', 'above', 'off', 'whom', 'will', 'again', 'same', 'an', 'than', 'so', 'only', 'shan', 'its', 'were', \"aren't\", \"haven't\", 'with', 'other', 'theirs', 'after', 'under', 'weren', 'both', \"needn't\", 'the', \"shouldn't\", 'been', 'ourselves', 'these', 'we', 'at', 'them', 'below', \"isn't\", 'such', 'mustn', 'can', 'am', 'few', 'our', \"hadn't\", 'isn', \"you've\", 'between', \"you'd\", 'should', 'he', 'why', 'from', 'until', 'y', 'him', 'before', 'don', 'and', 'no', 'her', 'myself', 'down', 'needn', 'nor', \"mustn't\", 'yours', 'm', 'ma', 'on', 'if', 'is', 'but', \"it's\", 'over', 'just', \"didn't\", 'was', 'having', 'very', 'me', 'all', 'o', 'to', 'hadn', 'have', 'those', 'wouldn', 'she', 'himself', 'then', 'when', \"you'll\", 'won', \"hasn't\", 'of', 'they', 'which', \"don't\", 'own', 'how', 'most', 'his', 'that', \"she's\", 'during', 'did', 'hasn', 'now', \"weren't\", 've', 'doing', \"couldn't\", 'there', 'not', \"wouldn't\", 'more', 'for', \"mightn't\", 't', 'it', 'their', 'some', 'by', 'doesn', 'you', 'hers', 'being', 'yourself', 'my', 'who', 'has', 'does', 'yourselves', 'up', 'shouldn', 're', 'as', 'themselves', \"doesn't\", 'couldn', 'about', 'where', 's', 'too', \"won't\", 'against', 'once', 'further', 'through', 'didn', 'mightn', 'your', 'or', 'here', 'haven', 'do', \"wasn't\", \"shan't\", 'in', 'itself'}\n"
     ]
    }
   ],
   "source": [
    "stop_words =set(stopwords.words('english'))    # set of stopwords\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][1]      #html tags are present in review data. Example is given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f05be90cfa4659b8625144e9e48fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=34707.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "i=0\n",
    "lemmatizer_word = WordNetLemmatizer() \n",
    "x_train_pre_processed = []\n",
    "all_positive_word_train = []\n",
    "all_negative_words_train = []\n",
    "for sent in tqdm(x_train.values):\n",
    "    filtered_sentence=[]\n",
    "#     print(sent)\n",
    "    sent = clearHtml(sent)\n",
    "    sent=  clearPunc(sent)\n",
    "    sent = decontracted(sent)\n",
    "    sent = clearRestSingleQuotes(sent)\n",
    "    for words in sent.split():\n",
    "        for clear_words in clearPunc(words).split():\n",
    "            if ((clear_words.isalpha())) & (len(clear_words)>2):\n",
    "                if (clear_words.lower() not in stop_words):\n",
    "#                     s = (ps.stem(clear_words.lower())).encode('utf8')      #PorterStemmer\n",
    "#                     s = (sno.stem(clear_words.lower())).encode('utf8')      #Snowball Stemmer\n",
    "                      s = (lemmatizer_word.lemmatize(clear_words.lower())).encode('utf8')      # Lemmantizer\n",
    "                      filtered_sentence.append(s)\n",
    "                      if (y_train.values)[i]:\n",
    "                            all_positive_word_train.append(s)\n",
    "                      else:\n",
    "                            all_negative_words_train.append(s)\n",
    "        str = b\" \".join(filtered_sentence)\n",
    "#     print(str)\n",
    "#     print('-'*90)\n",
    "    x_train_pre_processed.append(str)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'know film made react viscerally perhaps character unlikable compelling enough care perhaps disorganized storyline perhaps fact rob lowe wore long dangly earring eyeliner perhaps point movie break song perhaps never perhaps everything garish hyperbole perhaps character pump fist driving away camera fade know made hate mean trying watch willing find'\n",
      "------------------------------------------------------------------------------------------\n",
      "[b'loved', b'movie', b'beginning', b'end', b'musician', b'let', b'drug', b'get', b'way', b'thing']\n",
      "------------------------------------------------------------------------------------------\n",
      "Most positive words [(b'film', 34495), (b'movie', 31163), (b'one', 19737), (b'like', 12607), (b'time', 11215), (b'good', 10515), (b'story', 9798), (b'character', 9720), (b'would', 9093), (b'great', 9083), (b'see', 8876), (b'well', 8847), (b'get', 7777), (b'make', 7718), (b'also', 7581), (b'really', 7387), (b'scene', 7084), (b'life', 6948), (b'show', 6711), (b'even', 6633)]\n",
      "------------------------------------------------------------------------------------------\n",
      "[b'blob', b'start', b'one', b'bizarre', b'theme', b'song', b'ever', b'sung', b'uncredited', b'burt']\n",
      "------------------------------------------------------------------------------------------\n",
      "Most negative words [(b'movie', 40711), (b'film', 30303), (b'one', 18934), (b'like', 15796), (b'would', 12499), (b'even', 10652), (b'time', 10430), (b'good', 10297), (b'bad', 10255), (b'character', 9898), (b'get', 9343), (b'make', 9000), (b'really', 8429), (b'scene', 8032), (b'could', 7926), (b'see', 7759), (b'story', 7621), (b'much', 7038), (b'people', 6617), (b'thing', 6522)]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_pre_processed[1])\n",
    "print('-'*90) \n",
    "print(all_positive_word_train[0:10])\n",
    "print('-'*90)\n",
    "freq_dist_positive =nltk.FreqDist(all_positive_word_train)\n",
    "print('Most positive words',freq_dist_positive.most_common(20))\n",
    "print('-'*90)\n",
    "print(all_negative_words_train[0:10])\n",
    "print('-'*90)\n",
    "freq_dist_negative =nltk.FreqDist(all_negative_words_train)\n",
    "print('Most negative words',freq_dist_negative.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- Few words are there in negative and positive both like 'good', which actually positive word in real life scenario so it might be chances that it used with not and not is removed in stopwords.\n",
    "- To prevent that I am removing not from set of stopwords and re-run the code to check whether my observation is correct or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "#removing stop words like \"not\" should be avoided before building n-grams\n",
    "\n",
    "print(len(stop_words))\n",
    "stop_words.remove('not')       #removing not words from stop words\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c32dca9f77e4503af4361286dbfd8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=34707.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "i=0\n",
    "lemmatizer_word = WordNetLemmatizer() \n",
    "x_train_pre_processed = []\n",
    "all_positive_word_train = []\n",
    "all_negative_words_train = []\n",
    "for sent in tqdm(x_train.values):\n",
    "    filtered_sentence=[]\n",
    "#     print(sent)\n",
    "    sent = clearHtml(sent)\n",
    "    sent=  clearPunc(sent)\n",
    "    sent = decontracted(sent)\n",
    "    sent = clearRestSingleQuotes(sent)\n",
    "    for words in sent.split():\n",
    "        for clear_words in clearPunc(words).split():\n",
    "            if ((clear_words.isalpha())) & (len(clear_words)>2):\n",
    "                if (clear_words.lower() not in stop_words):\n",
    "#                     s = (ps.stem(clear_words.lower())).encode('utf8')      #PorterStemmer\n",
    "#                     s = (sno.stem(clear_words.lower())).encode('utf8')      #Snowball Stemmer\n",
    "                      s = (lemmatizer_word.lemmatize(clear_words.lower())).encode('utf8')      # Lemmantizer\n",
    "                      filtered_sentence.append(s)\n",
    "                      if (y_train.values)[i]:\n",
    "                            all_positive_word_train.append(s)\n",
    "                      else:\n",
    "                            all_negative_words_train.append(s)\n",
    "        str = b\" \".join(filtered_sentence)\n",
    "#     print(str)\n",
    "#     print('-'*90)\n",
    "    x_train_pre_processed.append(str)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'not know film made react viscerally perhaps character unlikable not compelling enough care perhaps disorganized storyline perhaps fact rob lowe wore long dangly earring eyeliner perhaps point movie break song perhaps never perhaps everything garish hyperbole perhaps character pump fist driving away camera fade not know made hate mean trying watch not willing find'\n",
      "------------------------------------------------------------------------------------------\n",
      "[b'loved', b'movie', b'beginning', b'end', b'musician', b'let', b'drug', b'get', b'way', b'thing']\n",
      "------------------------------------------------------------------------------------------\n",
      "Most positive words [(b'not', 38169), (b'film', 34495), (b'movie', 31163), (b'one', 19737), (b'like', 12607), (b'time', 11215), (b'good', 10515), (b'story', 9798), (b'character', 9720), (b'would', 9093), (b'great', 9083), (b'see', 8876), (b'well', 8847), (b'get', 7777), (b'make', 7718), (b'also', 7581), (b'really', 7387), (b'scene', 7084), (b'life', 6948), (b'show', 6711)]\n",
      "------------------------------------------------------------------------------------------\n",
      "[b'blob', b'start', b'one', b'bizarre', b'theme', b'song', b'ever', b'sung', b'uncredited', b'burt']\n",
      "------------------------------------------------------------------------------------------\n",
      "Most negative words [(b'not', 50031), (b'movie', 40711), (b'film', 30303), (b'one', 18934), (b'like', 15796), (b'would', 12499), (b'even', 10652), (b'time', 10430), (b'good', 10297), (b'bad', 10255), (b'character', 9898), (b'get', 9343), (b'make', 9000), (b'really', 8429), (b'scene', 8032), (b'could', 7926), (b'see', 7759), (b'story', 7621), (b'much', 7038), (b'people', 6617)]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_pre_processed[1])\n",
    "print('-'*90) \n",
    "print(all_positive_word_train[0:10])\n",
    "print('-'*90)\n",
    "freq_dist_positive =nltk.FreqDist(all_positive_word_train)\n",
    "print('Most positive words',freq_dist_positive.most_common(20))\n",
    "print('-'*90)\n",
    "print(all_negative_words_train[0:10])\n",
    "print('-'*90)\n",
    "freq_dist_negative =nltk.FreqDist(all_negative_words_train)\n",
    "print('Most negative words',freq_dist_negative.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae6621706514044bb9680e54500a110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=14875.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "i=0\n",
    "lemmatizer_word = WordNetLemmatizer() \n",
    "x_test_pre_processed = []\n",
    "all_positive_words_test = []\n",
    "all_negative_words_test = []\n",
    "for sent in tqdm(x_test.values):\n",
    "    filtered_sentence=[]\n",
    "#     print(sent)\n",
    "    sent = clearHtml(sent)\n",
    "    sent=  clearPunc(sent)\n",
    "    sent = decontracted(sent)\n",
    "    sent = clearRestSingleQuotes(sent)\n",
    "    for words in sent.split():\n",
    "        for clear_words in clearPunc(words).split():\n",
    "            if ((clear_words.isalpha())) & (len(clear_words)>2):\n",
    "                if (clear_words.lower() not in stop_words):\n",
    "#                     s = (ps.stem(clear_words.lower())).encode('utf8')      #PorterStemmer\n",
    "#                     s = (sno.stem(clear_words.lower())).encode('utf8')      #Snowball Stemmer\n",
    "                      s = (lemmatizer_word.lemmatize(clear_words.lower())).encode('utf8')      # Lemmantizer\n",
    "                      filtered_sentence.append(s)\n",
    "                      if (y_test.values)[i]:\n",
    "                            all_positive_words_test.append(s)\n",
    "                      else:\n",
    "                            all_negative_words_test.append(s)\n",
    "        str = b\" \".join(filtered_sentence)\n",
    "#     print(str)\n",
    "#     print('-'*90)\n",
    "    x_test_pre_processed.append(str)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'guest future tell fascinating story time travel friendship battle good evil small budget child actor special effect something spielberg lucas learn sixth grader kolya nick gerasimov find time machine basement decrepit building travel year future discovers near perfect utopian society robot play guitar write poetry everyone kind people enjoy everything technology offer alice daughter prominent scientist invented device called mielophone allows read mind human animal device put good bad use depending whose hand fall two evil space pirate saturn want rule universe attempt steal mielophone fall hand century school boy nick pirate hot track travel back time followed pirate alice chaos confusion funny situation follow luckless pirate try blend earthling alice enrolls school nick go demonstrates superhuman ability class catch alice not know nick look like pirate also pirate able change appearance turn literally anyone hmm wonder james cameron got idea terminator get nick mielophone first excellent plot non stop adventure great soundtrack wish hollywood made kid movie like one'\n",
      "------------------------------------------------------------------------------------------\n",
      "[b'guest', b'future', b'tell', b'fascinating', b'story', b'time', b'travel', b'friendship', b'battle', b'good']\n",
      "------------------------------------------------------------------------------------------\n",
      "Most positive words [(b'not', 16472), (b'film', 15056), (b'movie', 13469), (b'one', 8437), (b'like', 5522), (b'time', 5035), (b'good', 4520), (b'story', 4344), (b'character', 4245), (b'would', 4030), (b'see', 3998), (b'well', 3939), (b'great', 3854), (b'make', 3475), (b'get', 3372), (b'really', 3316), (b'also', 3180), (b'even', 2940), (b'scene', 2938), (b'life', 2914)]\n",
      "------------------------------------------------------------------------------------------\n",
      "[b'soul', b'plane', b'horrible', b'attempt', b'comedy', b'appeal', b'people', b'thick', b'skull', b'bloodshot']\n",
      "------------------------------------------------------------------------------------------\n",
      "Most negative words [(b'not', 21256), (b'movie', 17116), (b'film', 12963), (b'one', 7929), (b'like', 6863), (b'would', 5287), (b'time', 4519), (b'even', 4444), (b'good', 4330), (b'bad', 4308), (b'character', 4263), (b'get', 3973), (b'make', 3845), (b'really', 3785), (b'story', 3334), (b'could', 3317), (b'scene', 3241), (b'see', 3220), (b'much', 2938), (b'thing', 2840)]\n"
     ]
    }
   ],
   "source": [
    "print(x_test_pre_processed[1])\n",
    "print('-'*90) \n",
    "print(all_positive_words_test[0:10])\n",
    "print('-'*90)\n",
    "freq_dist_positive =nltk.FreqDist(all_positive_words_test)\n",
    "print('Most positive words',freq_dist_positive.most_common(20))\n",
    "print('-'*90)\n",
    "print(all_negative_words_test[0:10])\n",
    "print('-'*90)\n",
    "freq_dist_negative =nltk.FreqDist(all_negative_words_test)\n",
    "print('Most negative words',freq_dist_negative.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>[3.2] Preprocessing Review Summary</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So our early observation was correct not appear 50031 times in negative words so it might be appear as not good or not like "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4.1] Bag of Words (BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34707, 2218175)\n",
      "(14875, 2218175)\n"
     ]
    }
   ],
   "source": [
    "# creating BOW wit bigram\n",
    "count_vect = CountVectorizer(ngram_range=(1,2))\n",
    "x_train_count = count_vect.fit_transform(x_train_pre_processed)\n",
    "x_test_count = count_vect.transform(x_test_pre_processed)\n",
    "print(x_train_count.get_shape())\n",
    "print(x_test_count.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaa',\n",
       " 'aaa ball',\n",
       " 'aaa even',\n",
       " 'aaa favorite',\n",
       " 'aaa jawani',\n",
       " 'aaa level',\n",
       " 'aaa not',\n",
       " 'aaa yeah',\n",
       " 'aaaaaaaaaaaahhhhhhhhhhhhhh',\n",
       " 'aaaaaaaaaaaahhhhhhhhhhhhhh hurting',\n",
       " 'aaaaaaaargh',\n",
       " 'aaaaaaah',\n",
       " 'aaaaaaah saw',\n",
       " 'aaaaaaahhhhhhggg',\n",
       " 'aaaaagh',\n",
       " 'aaaaagh scene',\n",
       " 'aaaaah',\n",
       " 'aaaaah movie',\n",
       " 'aaaaah never',\n",
       " 'aaaaahhhh',\n",
       " 'aaaaahhhh get',\n",
       " 'aaaaatch',\n",
       " 'aaaaatch kah',\n",
       " 'aaaaaw',\n",
       " 'aaaaaw cry',\n",
       " 'aaaahhhhhh',\n",
       " 'aaaahhhhhh terrible',\n",
       " 'aaaahhhhhhh',\n",
       " 'aaaahhhhhhh run',\n",
       " 'aaaarrgh',\n",
       " 'aaaarrgh former',\n",
       " 'aaaawwwwww',\n",
       " 'aaaawwwwww well',\n",
       " 'aaaggghhhhhhh',\n",
       " 'aaaggghhhhhhh not',\n",
       " 'aaah',\n",
       " 'aaah friggin',\n",
       " 'aaah leg',\n",
       " 'aaahhhhhhh',\n",
       " 'aaahhhhhhh scene',\n",
       " 'aaall',\n",
       " 'aaall way',\n",
       " 'aaam',\n",
       " 'aaam going',\n",
       " 'aaargh',\n",
       " 'aaargh bad',\n",
       " 'aaargh dead',\n",
       " 'aaargh not',\n",
       " 'aab',\n",
       " 'aab tak',\n",
       " 'aachen',\n",
       " 'aachen palm',\n",
       " 'aachen two',\n",
       " 'aada',\n",
       " 'aada adhura',\n",
       " 'aag',\n",
       " 'aag actually',\n",
       " 'aag break',\n",
       " 'aag director',\n",
       " 'aag fail',\n",
       " 'aag figure',\n",
       " 'aag fire',\n",
       " 'aag hit',\n",
       " 'aag jugnu',\n",
       " 'aag make',\n",
       " 'aag never',\n",
       " 'aag not',\n",
       " 'aag one',\n",
       " 'aag put',\n",
       " 'aag sholay',\n",
       " 'aag take',\n",
       " 'aag totally',\n",
       " 'aag worst',\n",
       " 'aag worth',\n",
       " 'aage',\n",
       " 'aage haugland',\n",
       " 'aage pardey',\n",
       " 'aaghh',\n",
       " 'aaghh bee',\n",
       " 'aah',\n",
       " 'aah come',\n",
       " 'aah yes',\n",
       " 'aahe',\n",
       " 'aahe parsha',\n",
       " 'aahed',\n",
       " 'aahed theron',\n",
       " 'aahhh',\n",
       " 'aahhhh',\n",
       " 'aahhhh bless',\n",
       " 'aaila',\n",
       " 'aaila brilliantly',\n",
       " 'aailiyah',\n",
       " 'aailiyah pretty',\n",
       " 'aaja',\n",
       " 'aaja nachle',\n",
       " 'aajala',\n",
       " 'aajala ayala',\n",
       " 'aak',\n",
       " 'aak gag',\n",
       " 'aakash',\n",
       " 'aakash kenya',\n",
       " 'aake',\n",
       " 'aake sandgren',\n",
       " 'aakrosh',\n",
       " 'aakrosh second',\n",
       " 'aaliyah',\n",
       " 'aaliyah absolutely',\n",
       " 'aaliyah actually',\n",
       " 'aaliyah although',\n",
       " 'aaliyah blow',\n",
       " 'aaliyah fan',\n",
       " 'aaliyah filming',\n",
       " 'aaliyah last',\n",
       " 'aaliyah lestat',\n",
       " 'aaliyah make',\n",
       " 'aaliyah nice',\n",
       " 'aaliyah one',\n",
       " 'aaliyah perfect',\n",
       " 'aaliyah played',\n",
       " 'aaliyah role',\n",
       " 'aaliyah sadly',\n",
       " 'aaliyah sexy',\n",
       " 'aaliyah simply',\n",
       " 'aaliyah unfortunately',\n",
       " 'aaliyah untimely',\n",
       " 'aaliyah vampire',\n",
       " 'aalox',\n",
       " 'aames',\n",
       " 'aames cruz',\n",
       " 'aames film',\n",
       " 'aames young',\n",
       " 'aamir',\n",
       " 'aamir acting',\n",
       " 'aamir face',\n",
       " 'aamir ghulam',\n",
       " 'aamir given',\n",
       " 'aamir khan',\n",
       " 'aamir playing',\n",
       " 'aamir prem',\n",
       " 'aamir salman',\n",
       " 'aamir steal',\n",
       " 'aamir still',\n",
       " 'aamir yet',\n",
       " 'aamto',\n",
       " 'aamto master',\n",
       " 'aan',\n",
       " 'aan men',\n",
       " 'aan pyasa',\n",
       " 'aankh',\n",
       " 'aankh give',\n",
       " 'aankhen',\n",
       " 'aankhen adapted',\n",
       " 'aankhen director',\n",
       " 'aankhen fails',\n",
       " 'aankhen manage',\n",
       " 'aankhen raja',\n",
       " 'aankhen remake',\n",
       " 'aaoon',\n",
       " 'aaoon fitting',\n",
       " 'aap',\n",
       " 'aap saroor',\n",
       " 'aap surror',\n",
       " 'aapke',\n",
       " 'aapke hain',\n",
       " 'aapkey',\n",
       " 'aapkey hain',\n",
       " 'aaran',\n",
       " 'aaran one',\n",
       " 'aardman',\n",
       " 'aardman animation',\n",
       " 'aardman character',\n",
       " 'aardman could',\n",
       " 'aardman creating',\n",
       " 'aardman duo',\n",
       " 'aardman dynamic',\n",
       " 'aardman film',\n",
       " 'aardman lazed',\n",
       " 'aardman masterpiece',\n",
       " 'aardman movie',\n",
       " 'aardman original',\n",
       " 'aardman released',\n",
       " 'aardman studio',\n",
       " 'aardman style',\n",
       " 'aardman team',\n",
       " 'aardman would',\n",
       " 'aardvark',\n",
       " 'aardvark dog',\n",
       " 'aardvark fighting',\n",
       " 'aardvark trying',\n",
       " 'aardvark unfortunately',\n",
       " 'aarf',\n",
       " 'aarf show',\n",
       " 'aargh',\n",
       " 'aargh gun',\n",
       " 'aargh let',\n",
       " 'aargh superman',\n",
       " 'aarika',\n",
       " 'aarika well',\n",
       " 'aaron',\n",
       " 'aaron advice',\n",
       " 'aaron altman',\n",
       " 'aaron anchor',\n",
       " 'aaron another',\n",
       " 'aaron back',\n",
       " 'aaron badly',\n",
       " 'aaron bank',\n",
       " 'aaron blood',\n",
       " 'aaron boone',\n",
       " 'aaron brook',\n",
       " 'aaron brought',\n",
       " 'aaron carter',\n",
       " 'aaron character',\n",
       " 'aaron christian',\n",
       " 'aaron cinematography',\n",
       " 'aaron concert',\n",
       " 'aaron cory',\n",
       " 'aaron cruel',\n",
       " 'aaron curb',\n",
       " 'aaron decent',\n",
       " 'aaron directed',\n",
       " 'aaron eckhardt',\n",
       " 'aaron eckhart',\n",
       " 'aaron escape',\n",
       " 'aaron fors',\n",
       " 'aaron garlin',\n",
       " 'aaron get',\n",
       " 'aaron getting',\n",
       " 'aaron give',\n",
       " 'aaron given',\n",
       " 'aaron great',\n",
       " 'aaron hotties',\n",
       " 'aaron killing',\n",
       " 'aaron knews',\n",
       " 'aaron known',\n",
       " 'aaron lustig',\n",
       " 'aaron mandel',\n",
       " 'aaron mental',\n",
       " 'aaron michael',\n",
       " 'aaron mind',\n",
       " 'aaron miraculously',\n",
       " 'aaron neville',\n",
       " 'aaron norris',\n",
       " 'aaron not',\n",
       " 'aaron oliver',\n",
       " 'aaron overall',\n",
       " 'aaron paul',\n",
       " 'aaron pearl',\n",
       " 'aaron pederson',\n",
       " 'aaron peirce',\n",
       " 'aaron picked',\n",
       " 'aaron platt',\n",
       " 'aaron real',\n",
       " 'aaron running',\n",
       " 'aaron russo',\n",
       " 'aaron scates',\n",
       " 'aaron schneider',\n",
       " 'aaron seen',\n",
       " 'aaron seltzer',\n",
       " 'aaron sheritt',\n",
       " 'aaron sherritt',\n",
       " 'aaron show',\n",
       " 'aaron shown',\n",
       " 'aaron sings',\n",
       " 'aaron sorkin',\n",
       " 'aaron spelling',\n",
       " 'aaron start',\n",
       " 'aaron steve',\n",
       " 'aaron sudden',\n",
       " 'aaron though',\n",
       " 'aaron trip',\n",
       " 'aaron unfathomable',\n",
       " 'aaron upbringing',\n",
       " 'aaron vanek',\n",
       " 'aaron wake',\n",
       " 'aaron whole',\n",
       " 'aaron wonderfully',\n",
       " 'aaron would',\n",
       " 'aaron yamasato',\n",
       " 'aarp',\n",
       " 'aarp card',\n",
       " 'aarrrgh',\n",
       " 'aarrrgh never',\n",
       " 'aashok',\n",
       " 'aashok make',\n",
       " 'aasman',\n",
       " 'aasman niche',\n",
       " 'aatish',\n",
       " 'aatish kapadia',\n",
       " 'aaton',\n",
       " 'aaton god',\n",
       " 'aau',\n",
       " 'aau chin',\n",
       " 'aauugghh',\n",
       " 'aauugghh god',\n",
       " 'aavjo',\n",
       " 'aavjo vhala',\n",
       " 'aawip',\n",
       " 'aawip fails',\n",
       " 'aawip screenplay',\n",
       " 'aawip try',\n",
       " 'ab',\n",
       " 'ab alexandra',\n",
       " 'ab awesome',\n",
       " 'ab cbn',\n",
       " 'ab fat',\n",
       " 'ab played',\n",
       " 'ab rich',\n",
       " 'aba',\n",
       " 'aba mastermind',\n",
       " 'aback',\n",
       " 'aback appearance',\n",
       " 'aback arab',\n",
       " 'aback babbage',\n",
       " 'aback change',\n",
       " 'aback criticized',\n",
       " 'aback ethic',\n",
       " 'aback little',\n",
       " 'aback much',\n",
       " 'aback realizes',\n",
       " 'aback recommend',\n",
       " 'aback shear',\n",
       " 'aback shrinking',\n",
       " 'aback story',\n",
       " 'aback worker',\n",
       " 'aback writing',\n",
       " 'abadi',\n",
       " 'abadi shayesteh',\n",
       " 'abahy',\n",
       " 'abahy turn',\n",
       " 'abanazer',\n",
       " 'abanazer church',\n",
       " 'abanazer lovely',\n",
       " 'abandon',\n",
       " 'abandon alien',\n",
       " 'abandon arm',\n",
       " 'abandon attempt',\n",
       " 'abandon bunch',\n",
       " 'abandon cannot',\n",
       " 'abandon car',\n",
       " 'abandon care',\n",
       " 'abandon claim',\n",
       " 'abandon clear',\n",
       " 'abandon concentrate',\n",
       " 'abandon consistency',\n",
       " 'abandon cornfield',\n",
       " 'abandon crystina',\n",
       " 'abandon dying',\n",
       " 'abandon effort',\n",
       " 'abandon episode',\n",
       " 'abandon every',\n",
       " 'abandon everything',\n",
       " 'abandon evil',\n",
       " 'abandon front',\n",
       " 'abandon get',\n",
       " 'abandon heretofore',\n",
       " 'abandon high',\n",
       " 'abandon hit',\n",
       " 'abandon hollywood',\n",
       " 'abandon hope',\n",
       " 'abandon house',\n",
       " 'abandon humanity',\n",
       " 'abandon husband',\n",
       " 'abandon hyde',\n",
       " 'abandon idea',\n",
       " 'abandon japanese',\n",
       " 'abandon kermit',\n",
       " 'abandon life',\n",
       " 'abandon logic',\n",
       " 'abandon look',\n",
       " 'abandon looking',\n",
       " 'abandon magic',\n",
       " 'abandon making',\n",
       " 'abandon management',\n",
       " 'abandon mansion',\n",
       " 'abandon marriage',\n",
       " 'abandon meet',\n",
       " 'abandon men',\n",
       " 'abandon mistress',\n",
       " 'abandon movie',\n",
       " 'abandon music',\n",
       " 'abandon mutual',\n",
       " 'abandon native',\n",
       " 'abandon not',\n",
       " 'abandon notable',\n",
       " 'abandon nuance',\n",
       " 'abandon order',\n",
       " 'abandon pay',\n",
       " 'abandon personal',\n",
       " 'abandon post',\n",
       " 'abandon pretense',\n",
       " 'abandon pretext',\n",
       " 'abandon principle',\n",
       " 'abandon real',\n",
       " 'abandon reggae',\n",
       " 'abandon responsibility',\n",
       " 'abandon rhonda',\n",
       " 'abandon role',\n",
       " 'abandon search',\n",
       " 'abandon second',\n",
       " 'abandon shop',\n",
       " 'abandon side',\n",
       " 'abandon silent',\n",
       " 'abandon silently',\n",
       " 'abandon slapstick',\n",
       " 'abandon tactic',\n",
       " 'abandon technology',\n",
       " 'abandon territory',\n",
       " 'abandon think',\n",
       " 'abandon tuning',\n",
       " 'abandon viru',\n",
       " 'abandon want',\n",
       " 'abandon well',\n",
       " 'abandon within',\n",
       " 'abandon wounded',\n",
       " 'abandon young',\n",
       " 'abandoned',\n",
       " 'abandoned aerial',\n",
       " 'abandoned airplane',\n",
       " 'abandoned amusement',\n",
       " 'abandoned antique',\n",
       " 'abandoned art',\n",
       " 'abandoned artist',\n",
       " 'abandoned baby',\n",
       " 'abandoned birth',\n",
       " 'abandoned blackwell',\n",
       " 'abandoned bleak',\n",
       " 'abandoned boy',\n",
       " 'abandoned break',\n",
       " 'abandoned building',\n",
       " 'abandoned cabin',\n",
       " 'abandoned car',\n",
       " 'abandoned chapel',\n",
       " 'abandoned character',\n",
       " 'abandoned chess',\n",
       " 'abandoned church',\n",
       " 'abandoned city',\n",
       " 'abandoned civilized',\n",
       " 'abandoned close',\n",
       " 'abandoned coal',\n",
       " 'abandoned complex',\n",
       " 'abandoned convent',\n",
       " 'abandoned could',\n",
       " 'abandoned country',\n",
       " 'abandoned course',\n",
       " 'abandoned create',\n",
       " 'abandoned creed',\n",
       " 'abandoned cute',\n",
       " 'abandoned daughter',\n",
       " 'abandoned decent',\n",
       " 'abandoned desert',\n",
       " 'abandoned doctor',\n",
       " 'abandoned drama',\n",
       " 'abandoned driver',\n",
       " 'abandoned effort',\n",
       " 'abandoned egyptian',\n",
       " 'abandoned eight',\n",
       " 'abandoned especially',\n",
       " 'abandoned essential',\n",
       " 'abandoned everyone',\n",
       " 'abandoned exploited',\n",
       " 'abandoned fact',\n",
       " 'abandoned factory',\n",
       " 'abandoned family',\n",
       " 'abandoned father',\n",
       " 'abandoned favorite',\n",
       " 'abandoned film',\n",
       " 'abandoned filthy',\n",
       " 'abandoned first',\n",
       " 'abandoned fishing',\n",
       " 'abandoned funeral',\n",
       " 'abandoned future',\n",
       " 'abandoned garage',\n",
       " 'abandoned genius',\n",
       " 'abandoned german',\n",
       " 'abandoned ghost',\n",
       " 'abandoned gold',\n",
       " 'abandoned good',\n",
       " 'abandoned graveyard',\n",
       " 'abandoned high',\n",
       " 'abandoned hotel',\n",
       " 'abandoned house',\n",
       " 'abandoned husband',\n",
       " 'abandoned infant',\n",
       " 'abandoned institution',\n",
       " 'abandoned island',\n",
       " 'abandoned jungle',\n",
       " 'abandoned junk',\n",
       " 'abandoned kill',\n",
       " 'abandoned king',\n",
       " 'abandoned later',\n",
       " 'abandoned leaf',\n",
       " 'abandoned leaving',\n",
       " 'abandoned life',\n",
       " 'abandoned london',\n",
       " 'abandoned long',\n",
       " 'abandoned lost',\n",
       " 'abandoned lot',\n",
       " 'abandoned lover',\n",
       " 'abandoned lusty',\n",
       " 'abandoned luther',\n",
       " 'abandoned mail',\n",
       " 'abandoned man',\n",
       " 'abandoned mansion',\n",
       " 'abandoned mere',\n",
       " 'abandoned michigan',\n",
       " 'abandoned mine',\n",
       " 'abandoned monastery',\n",
       " 'abandoned moral',\n",
       " 'abandoned mother',\n",
       " 'abandoned mountain',\n",
       " 'abandoned movie',\n",
       " 'abandoned napier',\n",
       " 'abandoned naturally',\n",
       " 'abandoned never',\n",
       " 'abandoned next',\n",
       " 'abandoned not',\n",
       " 'abandoned old',\n",
       " 'abandoned one',\n",
       " 'abandoned order',\n",
       " 'abandoned orphan',\n",
       " 'abandoned parent',\n",
       " 'abandoned part',\n",
       " 'abandoned pay',\n",
       " 'abandoned penitentiary',\n",
       " 'abandoned picture',\n",
       " 'abandoned place',\n",
       " 'abandoned play',\n",
       " 'abandoned plotlines',\n",
       " 'abandoned plush',\n",
       " 'abandoned poor',\n",
       " 'abandoned pretending',\n",
       " 'abandoned prison',\n",
       " 'abandoned project',\n",
       " 'abandoned protagonist',\n",
       " 'abandoned quickly',\n",
       " 'abandoned real',\n",
       " 'abandoned refugee',\n",
       " 'abandoned remake',\n",
       " 'abandoned resolved',\n",
       " 'abandoned rich',\n",
       " 'abandoned rotting',\n",
       " 'abandoned run',\n",
       " 'abandoned russian',\n",
       " 'abandoned scene',\n",
       " 'abandoned school',\n",
       " 'abandoned see',\n",
       " 'abandoned seems',\n",
       " 'abandoned shack',\n",
       " 'abandoned shi',\n",
       " 'abandoned ship',\n",
       " 'abandoned short',\n",
       " 'abandoned shot',\n",
       " 'abandoned since',\n",
       " 'abandoned site',\n",
       " 'abandoned small',\n",
       " 'abandoned spaceship',\n",
       " 'abandoned spaniel',\n",
       " 'abandoned spark',\n",
       " 'abandoned spooky',\n",
       " 'abandoned station',\n",
       " 'abandoned stock',\n",
       " 'abandoned suddenly',\n",
       " 'abandoned summer',\n",
       " 'abandoned swimming',\n",
       " 'abandoned tacking',\n",
       " 'abandoned tell',\n",
       " 'abandoned theater',\n",
       " 'abandoned three',\n",
       " 'abandoned time',\n",
       " 'abandoned tired',\n",
       " 'abandoned toxic',\n",
       " 'abandoned train',\n",
       " 'abandoned troubled',\n",
       " 'abandoned truck',\n",
       " 'abandoned two',\n",
       " 'abandoned underground',\n",
       " 'abandoned unfinished',\n",
       " 'abandoned vacation',\n",
       " 'abandoned video',\n",
       " 'abandoned village',\n",
       " 'abandoned voice',\n",
       " 'abandoned wanted',\n",
       " 'abandoned war',\n",
       " 'abandoned warehouse',\n",
       " 'abandoned wedding',\n",
       " 'abandoned wife',\n",
       " 'abandoned wise',\n",
       " 'abandoned within',\n",
       " 'abandoned without',\n",
       " 'abandoned wood',\n",
       " 'abandoned would',\n",
       " 'abandoned year',\n",
       " 'abandoned yokai',\n",
       " 'abandoning',\n",
       " 'abandoning artistic',\n",
       " 'abandoning child',\n",
       " 'abandoning day',\n",
       " 'abandoning destroys',\n",
       " 'abandoning direction',\n",
       " 'abandoning essentially',\n",
       " 'abandoning film',\n",
       " 'abandoning historical',\n",
       " 'abandoning humanity',\n",
       " 'abandoning job',\n",
       " 'abandoning men',\n",
       " 'abandoning mosaic',\n",
       " 'abandoning one',\n",
       " 'abandoning parental',\n",
       " 'abandoning project',\n",
       " 'abandoning rule',\n",
       " 'abandoning sick',\n",
       " 'abandoning small',\n",
       " 'abandoning tito',\n",
       " 'abandoning trip',\n",
       " 'abandoning viewer',\n",
       " 'abandonment',\n",
       " 'abandonment adult',\n",
       " 'abandonment believe',\n",
       " 'abandonment child',\n",
       " 'abandonment common',\n",
       " 'abandonment course',\n",
       " 'abandonment courtenay',\n",
       " 'abandonment difficult',\n",
       " 'abandonment ego',\n",
       " 'abandonment family',\n",
       " 'abandonment great',\n",
       " 'abandonment money',\n",
       " 'abandonment mother',\n",
       " 'abandonment need',\n",
       " 'abandonment not',\n",
       " 'abandonment return',\n",
       " 'abandonment sewer',\n",
       " 'abandonment sexual',\n",
       " 'abandonment society',\n",
       " 'abandonment term',\n",
       " 'abandonment think',\n",
       " 'abandonment throw',\n",
       " 'abandonment tried',\n",
       " 'abandonment twice',\n",
       " 'abandonment yet',\n",
       " 'abashed',\n",
       " 'abashed brought',\n",
       " 'abashidze',\n",
       " 'abashidze star',\n",
       " 'abatement',\n",
       " 'abatement agony',\n",
       " 'abating',\n",
       " 'abating quite',\n",
       " 'abattoir',\n",
       " 'abattoir plus',\n",
       " 'abba',\n",
       " 'abba become',\n",
       " 'abba captain',\n",
       " 'abba constantly',\n",
       " 'abba costume',\n",
       " 'abba daughter',\n",
       " 'abba delightful',\n",
       " 'abba fall',\n",
       " 'abba fame',\n",
       " 'abba horrible',\n",
       " 'abba kind',\n",
       " 'abba name',\n",
       " 'abba not',\n",
       " 'abba song',\n",
       " 'abba soundtrack',\n",
       " 'abba vikea',\n",
       " 'abbad',\n",
       " 'abbad khan',\n",
       " 'abbas',\n",
       " 'abbas ali',\n",
       " 'abbas khan',\n",
       " 'abbas kiarostami',\n",
       " 'abbas mastan',\n",
       " 'abbas mustan',\n",
       " 'abbas responsible',\n",
       " 'abbasi',\n",
       " 'abbasi edgar',\n",
       " 'abbe',\n",
       " 'abbe lane',\n",
       " 'abbey',\n",
       " 'abbey actually',\n",
       " 'abbey bad',\n",
       " 'abbey basically',\n",
       " 'abbey castle',\n",
       " 'abbey caught',\n",
       " 'abbey could',\n",
       " 'abbey destroyed',\n",
       " 'abbey fact',\n",
       " 'abbey film',\n",
       " 'abbey find',\n",
       " 'abbey flavia',\n",
       " 'abbey give',\n",
       " 'abbey go',\n",
       " 'abbey hateful',\n",
       " 'abbey julia',\n",
       " 'abbey kells',\n",
       " 'abbey let',\n",
       " 'abbey live',\n",
       " 'abbey looked',\n",
       " 'abbey mansfield',\n",
       " 'abbey much',\n",
       " 'abbey mum',\n",
       " 'abbey never',\n",
       " 'abbey odd',\n",
       " 'abbey one',\n",
       " 'abbey parody',\n",
       " 'abbey protect',\n",
       " 'abbey released',\n",
       " 'abbey ruin',\n",
       " 'abbey satirized',\n",
       " 'abbey scene',\n",
       " 'abbey school',\n",
       " 'abbey seat',\n",
       " 'abbey seen',\n",
       " 'abbey shocked',\n",
       " 'abbey sit',\n",
       " 'abbey sort',\n",
       " 'abbey squire',\n",
       " 'abbey start',\n",
       " 'abbey success',\n",
       " 'abbey surely',\n",
       " 'abbey theatre',\n",
       " 'abbey thrown',\n",
       " 'abbey warning',\n",
       " 'abbie',\n",
       " 'abbie cornish',\n",
       " 'abbie hoffman',\n",
       " 'abbot',\n",
       " 'abbot apprentice',\n",
       " 'abbot awful',\n",
       " 'abbot build',\n",
       " 'abbot cameron',\n",
       " 'abbot cellach',\n",
       " 'abbot costello',\n",
       " 'abbot enough',\n",
       " 'abbot especially',\n",
       " 'abbot final',\n",
       " 'abbot graf',\n",
       " 'abbot hugo',\n",
       " 'abbot impersonated',\n",
       " 'abbot kell',\n",
       " 'abbot kells',\n",
       " 'abbot loving',\n",
       " 'abbot name',\n",
       " 'abbot township',\n",
       " 'abbot white',\n",
       " 'abbott',\n",
       " 'abbott always',\n",
       " 'abbott buddy',\n",
       " 'abbott carrey',\n",
       " 'abbott costell',\n",
       " 'abbott costello',\n",
       " 'abbott dinklepuss',\n",
       " 'abbott feeding',\n",
       " 'abbott get',\n",
       " 'abbott jack',\n",
       " 'abbott kathryn',\n",
       " 'abbott lou',\n",
       " 'abbott mistake',\n",
       " 'abbott not',\n",
       " 'abbott plot',\n",
       " 'abbott reliving',\n",
       " 'abbott though',\n",
       " 'abbott true',\n",
       " 'abbott usual',\n",
       " 'abbott white',\n",
       " 'abbotts',\n",
       " 'abbreviate',\n",
       " 'abbreviate title',\n",
       " 'abbreviated',\n",
       " 'abbreviated appears',\n",
       " 'abbreviated battle',\n",
       " 'abbreviated credit',\n",
       " 'abbreviated dsds',\n",
       " 'abbreviated episode',\n",
       " 'abbreviated film',\n",
       " 'abbreviated form',\n",
       " 'abbreviated length',\n",
       " 'abbreviated ramo',\n",
       " 'abbreviated wrong',\n",
       " 'abbreviating',\n",
       " 'abbreviating actual',\n",
       " 'abbu',\n",
       " 'abbu aba',\n",
       " 'abbu abbas',\n",
       " 'abby',\n",
       " 'abby blackmail',\n",
       " 'abby die',\n",
       " 'abby disappearing',\n",
       " 'abby engaged',\n",
       " 'abby final',\n",
       " 'abby find',\n",
       " 'abby fully',\n",
       " 'abby get',\n",
       " 'abby go',\n",
       " 'abby group',\n",
       " 'abby however',\n",
       " 'abby julia',\n",
       " 'abby life',\n",
       " 'abby looked',\n",
       " 'abby mum',\n",
       " 'abby not',\n",
       " 'abby plan',\n",
       " 'abby played',\n",
       " 'abby russell',\n",
       " 'abby say',\n",
       " 'abby sex',\n",
       " 'abby show',\n",
       " 'abby skin',\n",
       " 'abby something',\n",
       " 'abby took',\n",
       " 'abby true',\n",
       " 'abby uniform',\n",
       " 'abby worst',\n",
       " 'abbyss',\n",
       " 'abbyss anyway',\n",
       " 'abc',\n",
       " 'abc abc',\n",
       " 'abc actually',\n",
       " 'abc affiliate',\n",
       " 'abc afterschool',\n",
       " 'abc australian',\n",
       " 'abc award',\n",
       " 'abc back',\n",
       " 'abc basically',\n",
       " 'abc best',\n",
       " 'abc brings',\n",
       " 'abc brought',\n",
       " 'abc canceled',\n",
       " 'abc cancellation',\n",
       " 'abc cbs',\n",
       " 'abc celebration',\n",
       " 'abc chocking',\n",
       " 'abc classic',\n",
       " 'abc com',\n",
       " 'abc could',\n",
       " 'abc create',\n",
       " 'abc decided',\n",
       " 'abc disney',\n",
       " 'abc done',\n",
       " 'abc dropped',\n",
       " 'abc dvd',\n",
       " 'abc email',\n",
       " 'abc even',\n",
       " 'abc executive',\n",
       " 'abc faddish',\n",
       " 'abc family',\n",
       " 'abc far',\n",
       " 'abc fault',\n",
       " 'abc fighting',\n",
       " 'abc finally',\n",
       " 'abc forever',\n",
       " 'abc forgot',\n",
       " 'abc friday',\n",
       " 'abc get',\n",
       " 'abc given',\n",
       " 'abc giving',\n",
       " 'abc good',\n",
       " 'abc got',\n",
       " 'abc hennessy',\n",
       " 'abc http',\n",
       " 'abc huge',\n",
       " 'abc impressive',\n",
       " 'abc improv',\n",
       " 'abc inexplicably',\n",
       " 'abc know',\n",
       " 'abc lack',\n",
       " 'abc last',\n",
       " 'abc licensed',\n",
       " 'abc long',\n",
       " 'abc lost',\n",
       " 'abc loved',\n",
       " 'abc made',\n",
       " 'abc magic',\n",
       " 'abc make',\n",
       " 'abc message',\n",
       " 'abc movie',\n",
       " 'abc much',\n",
       " 'abc murder',\n",
       " 'abc mystery',\n",
       " 'abc near',\n",
       " 'abc net',\n",
       " 'abc network',\n",
       " 'abc never',\n",
       " 'abc new',\n",
       " 'abc not',\n",
       " 'abc one',\n",
       " 'abc owned',\n",
       " 'abc picked',\n",
       " 'abc playing',\n",
       " 'abc pretty',\n",
       " 'abc program',\n",
       " 'abc proud',\n",
       " 'abc quoted',\n",
       " 'abc reality',\n",
       " 'abc regularly',\n",
       " 'abc release',\n",
       " 'abc repeated',\n",
       " 'abc replace',\n",
       " 'abc reported',\n",
       " 'abc restaurant',\n",
       " 'abc satred',\n",
       " 'abc school',\n",
       " 'abc sears',\n",
       " 'abc seeing',\n",
       " 'abc series',\n",
       " 'abc show',\n",
       " 'abc showing',\n",
       " 'abc small',\n",
       " 'abc straight',\n",
       " 'abc sunday',\n",
       " 'abc tacit',\n",
       " 'abc taken',\n",
       " 'abc tgif',\n",
       " 'abc thought',\n",
       " 'abc trying',\n",
       " 'abc two',\n",
       " 'abc usa',\n",
       " 'abc version',\n",
       " 'abc video',\n",
       " 'abc website',\n",
       " 'abc week',\n",
       " 'abc worst',\n",
       " 'abc would',\n",
       " 'abc year',\n",
       " 'abc zucker',\n",
       " 'abcd',\n",
       " 'abcd bachelor',\n",
       " 'abd',\n",
       " 'abd delightful',\n",
       " 'abd present',\n",
       " 'abdalla',\n",
       " 'abdalla older',\n",
       " 'abdic',\n",
       " 'abdic bosnian',\n",
       " 'abdic prevented',\n",
       " 'abdicates',\n",
       " 'abdicates awful',\n",
       " 'abdomen',\n",
       " 'abdomen finish',\n",
       " 'abdomen pull',\n",
       " 'abdomen sure',\n",
       " 'abdominal',\n",
       " 'abdominal agony',\n",
       " 'abdominal tumor',\n",
       " 'abdoo',\n",
       " 'abdoo hysterical',\n",
       " 'abduct',\n",
       " 'abduct believing',\n",
       " 'abduct first',\n",
       " 'abduct henchman',\n",
       " 'abduct lad',\n",
       " 'abduct lovely',\n",
       " 'abduct people',\n",
       " 'abduct ugly',\n",
       " 'abducted',\n",
       " 'abducted alien',\n",
       " 'abducted alley',\n",
       " 'abducted arab',\n",
       " 'abducted asian',\n",
       " 'abducted dealer',\n",
       " 'abducted dozen',\n",
       " 'abducted ensure',\n",
       " 'abducted evil',\n",
       " 'abducted first',\n",
       " 'abducted fleeting',\n",
       " 'abducted forced',\n",
       " 'abducted gang',\n",
       " 'abducted group',\n",
       " 'abducted home',\n",
       " 'abducted hostage',\n",
       " 'abducted indian',\n",
       " 'abducted jeff',\n",
       " 'abducted killer',\n",
       " 'abducted leave',\n",
       " 'abducted little',\n",
       " 'abducted man',\n",
       " 'abducted menacing',\n",
       " 'abducted mexican',\n",
       " 'abducted mother',\n",
       " 'abducted nearly',\n",
       " 'abducted not',\n",
       " 'abducted one',\n",
       " 'abducted photographer',\n",
       " 'abducted preserved',\n",
       " 'abducted public',\n",
       " 'abducted quartet',\n",
       " 'abducted raped',\n",
       " 'abducted seduced',\n",
       " 'abducted serve',\n",
       " 'abducted service',\n",
       " 'abducted sexually',\n",
       " 'abducted slavery',\n",
       " 'abducted someone',\n",
       " 'abducted strange',\n",
       " 'abducted suddenly',\n",
       " 'abducted wife',\n",
       " 'abducted woman',\n",
       " 'abducting',\n",
       " 'abducting burying',\n",
       " ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting all list of features or words \n",
    "count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['absurd quite', 'absurd rather', 'absurd rating',\n",
       "       'absurd reaction', 'absurd reference', 'absurd regard',\n",
       "       'absurd renny', 'absurd result', 'absurd revelation',\n",
       "       'absurd ride', 'absurd ridiculous', 'absurd road',\n",
       "       'absurd romance', 'absurd rule', 'absurd said', 'absurd sake',\n",
       "       'absurd scenario', 'absurd scheider', 'absurd seemed',\n",
       "       'absurd self', 'absurd serious', 'absurd setting', 'absurd sight',\n",
       "       'absurd silliness', 'absurd sinister', 'absurd situation',\n",
       "       'absurd sivaji', 'absurd sometimes', 'absurd sound',\n",
       "       'absurd soundtrack', 'absurd space', 'absurd stagebound',\n",
       "       'absurd stealing', 'absurd story', 'absurd stupid', 'absurd style',\n",
       "       'absurd sucker', 'absurd suddenly', 'absurd superman',\n",
       "       'absurd surreal', 'absurd take', 'absurd ted', 'absurd tedious',\n",
       "       'absurd terrible', 'absurd theory', 'absurd thing', 'absurd think',\n",
       "       'absurd though', 'absurd thre', 'absurd tired', 'absurd trash',\n",
       "       'absurd turn', 'absurd turning', 'absurd twist', 'absurd two',\n",
       "       'absurd unbearable', 'absurd unbelievable', 'absurd usually',\n",
       "       'absurd valid', 'absurd view', 'absurd violence', 'absurd wait',\n",
       "       'absurd wasting', 'absurd way', 'absurd welcome', 'absurd well',\n",
       "       'absurd western', 'absurd without', 'absurd word', 'absurd work',\n",
       "       'absurd workload', 'absurd worse', 'absurd woven', 'absurd writer',\n",
       "       'absurd yes', 'absurd yet', 'absurd zoey', 'absurd zombie',\n",
       "       'absurd zone', 'absurdest', 'absurdest twisted', 'absurdism',\n",
       "       'absurdism animation', 'absurdism constitute',\n",
       "       'absurdism minimalism', 'absurdism positive', 'absurdist',\n",
       "       'absurdist comedy', 'absurdist commentary', 'absurdist dark',\n",
       "       'absurdist documentary', 'absurdist endurance', 'absurdist ethos',\n",
       "       'absurdist imagery', 'absurdist masterpiece', 'absurdist period',\n",
       "       'absurdist play', 'absurdist playwright', 'absurdist premise',\n",
       "       'absurdist puppet', 'absurdist sculpture', 'absurdist self',\n",
       "       'absurdist tendency', 'absurdist ultra', 'absurdist way',\n",
       "       'absurdist word', 'absurdit', 'absurdit would', 'absurdity',\n",
       "       'absurdity absurdism', 'absurdity absurdity', 'absurdity actor',\n",
       "       'absurdity adult', 'absurdity american', 'absurdity anyone',\n",
       "       'absurdity background', 'absurdity begin', 'absurdity behind',\n",
       "       'absurdity biggest', 'absurdity biting', 'absurdity bomb',\n",
       "       'absurdity bond', 'absurdity bureaucracy', 'absurdity character',\n",
       "       'absurdity cherry', 'absurdity chuckle', 'absurdity constitutes',\n",
       "       'absurdity cruelty', 'absurdity culture', 'absurdity day',\n",
       "       'absurdity despair', 'absurdity doggie', 'absurdity done',\n",
       "       'absurdity dry', 'absurdity elite', 'absurdity even',\n",
       "       'absurdity far', 'absurdity fast', 'absurdity favor',\n",
       "       'absurdity film', 'absurdity full', 'absurdity genuinely',\n",
       "       'absurdity going', 'absurdity hat', 'absurdity hole',\n",
       "       'absurdity inanity', 'absurdity instead', 'absurdity lastly',\n",
       "       'absurdity law', 'absurdity life', 'absurdity like',\n",
       "       'absurdity line', 'absurdity living', 'absurdity logic',\n",
       "       'absurdity make', 'absurdity men', 'absurdity mind',\n",
       "       'absurdity movie', 'absurdity nice', 'absurdity none',\n",
       "       'absurdity not', 'absurdity obscenity', 'absurdity performance',\n",
       "       'absurdity plot', 'absurdity point', 'absurdity pop',\n",
       "       'absurdity premise', 'absurdity pure', 'absurdity rather',\n",
       "       'absurdity realistic', 'absurdity really', 'absurdity revolving',\n",
       "       'absurdity rise', 'absurdity samantha', 'absurdity satire',\n",
       "       'absurdity see', 'absurdity shaw', 'absurdity simply',\n",
       "       'absurdity situation', 'absurdity something', 'absurdity sparkle',\n",
       "       'absurdity star', 'absurdity strictly', 'absurdity supposed',\n",
       "       'absurdity take', 'absurdity thing', 'absurdity three',\n",
       "       'absurdity time', 'absurdity together', 'absurdity truth',\n",
       "       'absurdity undermines', 'absurdity unlike', 'absurdity various',\n",
       "       'absurdity waiting', 'absurdity war', 'absurdity watched',\n",
       "       'absurdity within', 'absurdity work', 'absurdity woven',\n",
       "       'absurdity yet', 'absurdity zoolander', 'absurdly', 'absurdly bad',\n",
       "       'absurdly badly', 'absurdly complicated', 'absurdly convoluted',\n",
       "       'absurdly designed', 'absurdly entertaining', 'absurdly fake',\n",
       "       'absurdly frilly', 'absurdly grotesque', 'absurdly happy',\n",
       "       'absurdly high', 'absurdly hilarious', 'absurdly hot',\n",
       "       'absurdly idiosyncratic', 'absurdly interesting', 'absurdly long',\n",
       "       'absurdly loutish', 'absurdly low', 'absurdly outlandish',\n",
       "       'absurdly praised', 'absurdly ridiculous', 'absurdly simplistic',\n",
       "       'absurdly still', 'absurdly stupid', 'absurdly unbelievable',\n",
       "       'absurdly unreal', 'absurdly unrealistic', 'absurdly vanessa',\n",
       "       'absurdly wrong', 'absurdness', 'absurdness easily',\n",
       "       'absurdness serbian', 'abt', 'abt actually', 'abu', 'abu become',\n",
       "       'abu becomes', 'abu conrad', 'abu fight', 'abu garib', 'abu genie',\n",
       "       'abu ghraib', 'abu graib', 'abu hamza', 'abu john', 'abu played',\n",
       "       'abu put', 'abu suffer', 'abu sympathetic', 'abu thief',\n",
       "       'abu triumphantly', 'abudantly', 'abudantly clear', 'abuelita',\n",
       "       'abuelita altagracia', 'abuhab', 'abuhab periodically',\n",
       "       'abundance', 'abundance around', 'abundance astutely',\n",
       "       'abundance bad', 'abundance beautiful', 'abundance better',\n",
       "       'abundance blankfield', 'abundance bottom', 'abundance cameo',\n",
       "       'abundance camp', 'abundance carol', 'abundance cgi',\n",
       "       'abundance characterization', 'abundance charm', 'abundance cheap',\n",
       "       'abundance clich', 'abundance comic', 'abundance common',\n",
       "       'abundance concept', 'abundance corrupted', 'abundance death',\n",
       "       'abundance disease', 'abundance due', 'abundance ending',\n",
       "       'abundance enrich', 'abundance fact', 'abundance female',\n",
       "       'abundance film', 'abundance flaw', 'abundance flesh',\n",
       "       'abundance foul', 'abundance girl', 'abundance good',\n",
       "       'abundance gratuitous', 'abundance hair', 'abundance higher',\n",
       "       'abundance home', 'abundance incident', 'abundance killer',\n",
       "       'abundance martial', 'abundance material', 'abundance memorable',\n",
       "       'abundance monica', 'abundance movie', 'abundance naked',\n",
       "       'abundance narcissism', 'abundance next', 'abundance nudity',\n",
       "       'abundance one', 'abundance poor', 'abundance quality',\n",
       "       'abundance rocking', 'abundance ryan', 'abundance sex',\n",
       "       'abundance shock', 'abundance sleazy', 'abundance talk',\n",
       "       'abundance terrain', 'abundance thrill', 'abundance violence',\n",
       "       'abundance zombie', 'abundant', 'abundant believe',\n",
       "       'abundant classic', 'abundant day', 'abundant emotionally',\n",
       "       'abundant fact', 'abundant female', 'abundant flaw',\n",
       "       'abundant flipper', 'abundant happens', 'abundant house',\n",
       "       'abundant including', 'abundant nemesis', 'abundant nudity',\n",
       "       'abundant profane', 'abundant promise', 'abundant puzzle',\n",
       "       'abundant quantity', 'abundant racial', 'abundant rather',\n",
       "       'abundant raw', 'abundant recent', 'abundant reproduction',\n",
       "       'abundant resource', 'abundant symbolism', 'abundant usually',\n",
       "       'abundantly', 'abundantly clear', 'abundantly clearer',\n",
       "       'abundantly gifted', 'abundantly obvious', 'abundantly personally',\n",
       "       'abundantly rewarded', 'abundantly talented', 'abuse',\n",
       "       'abuse abandonment', 'abuse abuse', 'abuse according',\n",
       "       'abuse adoption', 'abuse adult', 'abuse affair', 'abuse affect',\n",
       "       'abuse alcohol', 'abuse although', 'abuse amanda', 'abuse another',\n",
       "       'abuse apparently', 'abuse attractive', 'abuse authority',\n",
       "       'abuse bad', 'abuse battered', 'abuse becomes', 'abuse begin',\n",
       "       'abuse birthday', 'abuse bloodshed', 'abuse bobby', 'abuse bore',\n",
       "       'abuse bos', 'abuse cameroon', 'abuse challenger', 'abuse child',\n",
       "       'abuse chronic', 'abuse church', 'abuse committed',\n",
       "       'abuse complaint', 'abuse completely', 'abuse constant',\n",
       "       'abuse coolest', 'abuse crap', 'abuse credit', 'abuse cropping',\n",
       "       'abuse cruelty', 'abuse cynical', 'abuse daughter', 'abuse dealt',\n",
       "       'abuse defames', 'abuse degradation', 'abuse deserted',\n",
       "       'abuse destroys', 'abuse deviousness', 'abuse disabled',\n",
       "       'abuse displaced', 'abuse domestic', 'abuse done', 'abuse drawn',\n",
       "       'abuse drug', 'abuse duress', 'abuse emasculating',\n",
       "       'abuse emotional', 'abuse end', 'abuse endured',\n",
       "       'abuse environment', 'abuse essentially', 'abuse etc',\n",
       "       'abuse even', 'abuse eventually', 'abuse ever', 'abuse excuse',\n",
       "       'abuse exist', 'abuse exploitation', 'abuse family',\n",
       "       'abuse fantastic', 'abuse father', 'abuse fecal', 'abuse film',\n",
       "       'abuse folk', 'abuse forced', 'abuse found', 'abuse frame',\n",
       "       'abuse frat', 'abuse fresh', 'abuse friend', 'abuse gave',\n",
       "       'abuse going', 'abuse good', 'abuse grandmother', 'abuse graphic',\n",
       "       'abuse guess', 'abuse guilt', 'abuse hand', 'abuse handicapped',\n",
       "       'abuse heaped', 'abuse heather', 'abuse hedonism', 'abuse hinted',\n",
       "       'abuse hitchcock', 'abuse hold', 'abuse horse', 'abuse humiliate',\n",
       "       'abuse humour', 'abuse hypocrisy', 'abuse implied',\n",
       "       'abuse includes', 'abuse increasingly', 'abuse inflicted',\n",
       "       'abuse innocent', 'abuse inspiration', 'abuse jackson',\n",
       "       'abuse jew', 'abuse joke', 'abuse keep', 'abuse keeping',\n",
       "       'abuse kid', 'abuse kidnapping', 'abuse killing', 'abuse knowing',\n",
       "       'abuse lawless', 'abuse leading', 'abuse let', 'abuse loneliness',\n",
       "       'abuse look', 'abuse looping', 'abuse lord', 'abuse make',\n",
       "       'abuse male', 'abuse manner', 'abuse may', 'abuse maybe',\n",
       "       'abuse mazzello', 'abuse mean', 'abuse mechanism', 'abuse medium',\n",
       "       'abuse men', 'abuse midst', 'abuse might', 'abuse miss',\n",
       "       'abuse movie', 'abuse must', 'abuse mutilated', 'abuse nature',\n",
       "       'abuse neglect', 'abuse never', 'abuse new', 'abuse not',\n",
       "       'abuse older', 'abuse one', 'abuse opposed', 'abuse overly',\n",
       "       'abuse paragraph', 'abuse parent', 'abuse perpetrator',\n",
       "       'abuse phony', 'abuse physical', 'abuse police', 'abuse position',\n",
       "       'abuse power', 'abuse presented', 'abuse privilege',\n",
       "       'abuse problem', 'abuse progress', 'abuse psychological',\n",
       "       'abuse rated', 'abuse rather', 'abuse realistic', 'abuse really',\n",
       "       'abuse received', 'abuse redemption', 'abuse refusal',\n",
       "       'abuse religion', 'abuse renouncing', 'abuse reviewer',\n",
       "       'abuse rough', 'abuse ruth', 'abuse scarred', 'abuse scene',\n",
       "       'abuse school', 'abuse second', 'abuse seemingly', 'abuse selfish',\n",
       "       'abuse send', 'abuse sense', 'abuse severe', 'abuse sex',\n",
       "       'abuse sexual', 'abuse shock', 'abuse shylock', 'abuse side',\n",
       "       'abuse simply', 'abuse single', 'abuse slow', 'abuse somehow',\n",
       "       'abuse someone', 'abuse soon', 'abuse sound', 'abuse speak',\n",
       "       'abuse start', 'abuse steely', 'abuse student', 'abuse stupid',\n",
       "       'abuse suffered', 'abuse suffers', 'abuse sufficient',\n",
       "       'abuse superior', 'abuse survive', 'abuse swope', 'abuse syrupy',\n",
       "       'abuse take', 'abuse talent', 'abuse technical', 'abuse teen',\n",
       "       'abuse tell', 'abuse thank', 'abuse think', 'abuse though',\n",
       "       'abuse tiananmen', 'abuse time', 'abuse topic', 'abuse torment',\n",
       "       'abuse torture', 'abuse towards', 'abuse treat', 'abuse try',\n",
       "       'abuse two', 'abuse ugly', 'abuse ultimately', 'abuse unconscious',\n",
       "       'abuse underling', 'abuse unnecesary', 'abuse verbally',\n",
       "       'abuse violence', 'abuse well', 'abuse west', 'abuse wife',\n",
       "       'abuse wii', 'abuse without', 'abuse woman', 'abuse word',\n",
       "       'abuse would', 'abuse wrong', 'abuse year', 'abuse yet',\n",
       "       'abuse young', 'abused', 'abused abandoned', 'abused abusive',\n",
       "       'abused adopted', 'abused adult', 'abused antwone',\n",
       "       'abused anyone', 'abused awakened', 'abused battered',\n",
       "       'abused begin', 'abused beginning', 'abused bellboy',\n",
       "       'abused best', 'abused boy', 'abused cat', 'abused child',\n",
       "       'abused childhood', 'abused chinese', 'abused completely',\n",
       "       'abused could', 'abused coveted', 'abused damaged',\n",
       "       'abused daughter', 'abused day', 'abused deaf', 'abused dildo',\n",
       "       'abused dog', 'abused drugged', 'abused drunk', 'abused drunken',\n",
       "       'abused employee', 'abused every', 'abused farm', 'abused father',\n",
       "       'abused fierce', 'abused film', 'abused getting', 'abused girl',\n",
       "       'abused hero', 'abused housewife', 'abused hurt',\n",
       "       'abused instrument', 'abused insulted', 'abused kid',\n",
       "       'abused large', 'abused largely', 'abused left', 'abused like',\n",
       "       'abused little', 'abused make', 'abused master', 'abused men',\n",
       "       'abused model', 'abused molested', 'abused mostly',\n",
       "       'abused mother', 'abused neglected', 'abused never', 'abused next',\n",
       "       'abused nice', 'abused not', 'abused often', 'abused one',\n",
       "       'abused others', 'abused phrase', 'abused picked',\n",
       "       'abused powerless', 'abused prison'], dtype='<U145')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_array = np.array(count_vect.get_feature_names())\n",
    "feature_array[5000:5660]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz',\n",
       "       'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz excuse',\n",
       "       'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz',\n",
       "       'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz ooops',\n",
       "       'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz', 'zzzzzzzzzzzzzzzzzz imdb',\n",
       "       'zzzzzzzzzzzzzzzzzz', 'zzzzzzzzzzzzz way', 'zzzzzzzzzzzzz',\n",
       "       'zzzzzzzzzzzz pop'], dtype='<U145')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting top 10 words with most appearance\n",
    "responses = feature_array\n",
    "tfidf_sorting = np.argsort(responses).flatten()[::-1]\n",
    "\n",
    "n = 10\n",
    "top_n = feature_array[tfidf_sorting][:n]\n",
    "top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5] Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.1] Selecting the right hyperparameter i.e. alpha using 10-fold C.V."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=10, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulate splitting a dataset of 25 observations into 5 folds\n",
    "kf = KFold(n_splits=10)\n",
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial model with alpha = 0.0001 have mean 85.14994723675876 and standard deviation 0.8514994723675876\n",
      "Multinomial model with alpha = 0.1 have mean 87.52123440246355 and standard deviation 0.8752123440246355\n",
      "Multinomial model with alpha = 0.1 have mean 87.52123440246355 and standard deviation 0.8752123440246355\n",
      "Multinomial model with alpha = 1 have mean 87.9361195313661 and standard deviation 0.879361195313661\n",
      "Multinomial model with alpha = 10 have mean 87.49239935339084 and standard deviation 0.8749239935339084\n",
      "Multinomial model with alpha = 20 have mean 87.1149557843208 and standard deviation 0.871149557843208\n",
      "Multinomial model with alpha = 200 have mean 84.9050377894402 and standard deviation 0.8490503778944021\n",
      "Multinomial model with alpha = 2000 have mean 79.04454197272253 and standard deviation 0.7904454197272253\n",
      "Multinomial model with alpha = 20000 have mean 68.15912247797102 and standard deviation 0.6815912247797102\n",
      "Multinomial model with alpha = 2000000 have mean 65.27211468926976 and standard deviation 0.6527211468926976\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.0001,00.1,0.1,1,10,20,200,2000,20000,2000000]    # List of some alpha values\n",
    "for i in alphas:\n",
    "    print('''Multinomial model with alpha = {} have mean {} and standard deviation {}''' \\\n",
    "          .format(i,(cross_val_score(MultinomialNB(alpha=i),x_train_count,y_train,cv=10).mean())*100,cross_val_score(MultinomialNB(alpha=i),x_train_count,y_train,cv=10).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "- Multinomial model with alpha = 1 have the highest mean accuracy and standard deviation\n",
    "- From alpha = 0.0001 to alpha = 1 mean accuracy increasing but after alpha =1 mean accuracy start decreasing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.2.] Select the model with best suitable hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB(alpha=1)\n",
    "model.fit(x_train_count,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9959086063330164"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_train_count,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test_count) \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [6] Performance Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [6.1] Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6639  765]\n",
      " [ 984 6487]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [6.2] Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8824201680672269"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [7] Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The given dataset is balanced\n",
    "- The given datset is belong to binary classification, value of output is either positive or negative, so we can convert it into ordinal numeric value\n",
    "- The given dataset have duplication problem, we check and drop duplicate value, keeping the first of them only.\n",
    "- We can't remove 'not' word from the review during removal of stopwords because there are high chance that user use not good , not like kind of combination\n",
    "- Bag of words technique could be used to convert word to vector\n",
    "- Dataset is split into training and test dataset by 70:30 ratio\n",
    "- Going to use Naive Bayes for practice purpose\n",
    "- In Naive Bayes, particularly Multinomial Naive Bayes because it is suitable for classification with discrete features (e.g., word counts for text classification)\n",
    "- 10 - fold c.v. is used to select the best hyperparameter i.e. alpha = 1\n",
    "- Multinomial Naive Bayes model is trained using training data and training data score 0.9959 on the same model, which is pretty decent\n",
    "- We had used two performance matrix \n",
    "1) Confusion Matrix\n",
    "2) Accuracy, since dataset is balanced\n",
    "-The model has accuracy of 0.8824 on test data, which is average performance "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
